{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"PG Collector","text":"<p>From Signals to Prediction \u2014 Lightweight Agent for AI-Powered PostgreSQL Intelligence</p>"},{"location":"#overview","title":"Overview","text":"<p>Stop reacting to database issues\u2014start predicting them.</p> <p>PG Collector is a lightweight metrics agent that extracts PostgreSQL telemetry and delivers it to configurable destinations \u2014 locally for evaluation, or streamed to our cloud platform where AI analyzes patterns and predicts issues before they impact your users.</p> <p>Single binary. Zero dependencies. 5-minute setup.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 PostgreSQL   \u2502 \u2500\u2500\u2500\u25b6 \u2502 PG Collector \u2502 \u2500\u2500\u2500\u25b6 \u2502   Burnside   \u2502 \u2500\u2500\u2500\u25b6 \u2502 Predictions  \u2502\n\u2502  Database    \u2502      \u2502   (Agent)    \u2502      \u2502    Cloud     \u2502      \u2502  &amp; Alerts    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"#two-editions","title":"Two Editions","text":""},{"location":"#demo-edition-free","title":"Demo Edition (Free)","text":"<ul> <li>Single binary, zero external dependencies</li> <li>Runs locally; all output stays on your machine</li> <li>Core PostgreSQL samplers: activity, database, and statements</li> <li>Export snapshots to your favorite LLM (ChatGPT, Claude, etc.) for instant analysis</li> <li>Perfect for evaluation, learning, and local development</li> </ul>"},{"location":"#commercial-edition-subscription","title":"Commercial Edition (Subscription)","text":"<p>Everything in Demo, plus:</p> <ul> <li>Up to 12 PostgreSQL metric samplers</li> <li>AI-powered health reports with prescriptions</li> <li>Real-time streaming to Burnside Cloud</li> <li>Interactive health dashboard with configuration audit</li> <li>Multi-database monitoring, PII detection, audit logging</li> <li>mTLS, AWS IAM, GCP IAM authentication</li> </ul>"},{"location":"#quick-install","title":"Quick Install","text":"Linux (x86_64)Linux (ARM64)macOS (Apple Silicon)macOS (Intel) <pre><code>curl -LO https://github.com/burnside-project/pg-collector/releases/latest/download/pg-collector-linux-amd64.tar.gz\ntar -xzf pg-collector-linux-amd64.tar.gz\nsudo mv pg-collector /usr/local/bin/\n</code></pre> <pre><code>curl -LO https://github.com/burnside-project/pg-collector/releases/latest/download/pg-collector-linux-arm64.tar.gz\ntar -xzf pg-collector-linux-arm64.tar.gz\nsudo mv pg-collector /usr/local/bin/\n</code></pre> <pre><code>curl -LO https://github.com/burnside-project/pg-collector/releases/latest/download/pg-collector-darwin-arm64.tar.gz\ntar -xzf pg-collector-darwin-arm64.tar.gz\nsudo mv pg-collector /usr/local/bin/\n</code></pre> <pre><code>curl -LO https://github.com/burnside-project/pg-collector/releases/latest/download/pg-collector-darwin-amd64.tar.gz\ntar -xzf pg-collector-darwin-amd64.tar.gz\nsudo mv pg-collector /usr/local/bin/\n</code></pre>"},{"location":"#choose-your-plan","title":"Choose Your Plan","text":"<p>Start small, scale as you grow. All commercial plans include predictive analytics and alerting.</p> Demo Starter Pro Business Enterprise Databases 1 1 Multiple Many Unlimited Sampling frequency Basic Standard Fast Faster Real-time Metric samplers Core (3) Core Extended Full All (12) AI insights \u2014 Summary Detailed Predictive Interactive Support Community Email Priority Email Business Hours 24/7 <p>See Subscription Plans for the full comparison including security features and sampler availability.</p> <p>Book a Demo View Documentation</p>"},{"location":"#ai-powered-prediction","title":"AI-Powered Prediction","text":"<p>The intelligence behind the insights. Our AI transforms raw database metrics into predictions you can act on.</p>"},{"location":"#what-the-ai-predicts","title":"What the AI Predicts","text":"Prediction Type What It Detects Connection Exhaustion Pool approaching limits based on growth patterns Replication Lag Spike Replica falling behind due to write surge Lock Contention Blocking chains forming from concurrent transactions Cache Pressure Buffer cache hit ratio degrading Vacuum Emergency Tables approaching transaction wraparound Query Degradation Execution plans changing, slow query emergence"},{"location":"#how-it-works","title":"How It Works","text":"<p>The AI engine continuously analyzes your PostgreSQL metrics, detects patterns, and delivers:</p> <ul> <li>Severity-rated alerts \u2014 Know what's critical vs. informational</li> <li>Confidence scoring \u2014 Understand how certain the prediction is</li> <li>Evidence-based reasoning \u2014 See the data points driving the alert</li> <li>Recommended actions \u2014 Get specific, actionable fix suggestions</li> </ul>"},{"location":"#features","title":"Features","text":""},{"location":"#what-we-capture","title":"What We Capture","text":"Category What You Learn How Fast Activity Which queries are running, waiting, or blocked Real-time Performance Slow queries, cache misses, I/O bottlenecks Continuous Replication Lag alerts before replicas fall behind Real-time Storage Table bloat and growth trends Periodic Background Vacuum health and checkpoint pressure Periodic"},{"location":"#built-for-production","title":"Built for Production","text":"Guarantee What It Means Memory Safe Configurable ceiling with automatic management\u2014never runaway Network Resilient Local buffering survives outages\u2014zero data loss Minimal Footprint Max 2 PostgreSQL connections, timeout-protected queries Secure by Default mTLS or IAM auth\u2014no passwords in config files <p>Learn more: Architecture Overview | Device Activation</p>"},{"location":"#connect-your-way","title":"Connect Your Way","text":"Method Best For Guide mTLS Certificates Self-managed PostgreSQL (most secure) Security Guide AWS IAM RDS, Aurora (passwordless) AWS Setup GCP IAM Cloud SQL (passwordless) GCP Setup"},{"location":"#quick-configuration","title":"Quick Configuration","text":"<pre><code># API key from admin console (activates automatically on first run)\napi_key: \"${API_KEY}\"\n\n# Your PostgreSQL databases\ndatabases:\n  - name: Production\n    postgres:\n      conn_string: \"postgres://pgcollector@your-db:5432/postgres?sslmode=verify-full\"\n      auth_method: cert\n      tls:\n        mode: verify-full\n        ca_file: /etc/pg-collector/certs/ca.crt\n        cert_file: /etc/pg-collector/certs/client.crt\n        key_file: /etc/pg-collector/certs/client.key\n</code></pre> <p>See Configuration Guide for all options.</p>"},{"location":"#health-monitoring","title":"Health &amp; Monitoring","text":"<pre><code># Basic health check\ncurl http://localhost:8080/health\n\n# Detailed status\ncurl http://localhost:8080/status\n\n# Prometheus metrics\ncurl http://localhost:8080/metrics\n</code></pre>"},{"location":"#support","title":"Support","text":"<ul> <li>Documentation: Browse this site</li> <li>Issues: GitHub Issues</li> <li>Sales: sales@burnsideproject.ai</li> <li>Support: support@burnsideproject.ai</li> </ul> <p> From Signals to Prediction. Stop reacting. Start predicting. <sub>AI-powered database observability by Burnside Project</sub> </p>"},{"location":"activation/","title":"Device Activation","text":"<p>PG Collector uses an IoT-style device activation model. Each collector instance is a \"device\" that activates once and maintains persistent identity.</p>"},{"location":"activation/#overview","title":"Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Config    \u2502 \u2500\u2500\u25b6 \u2502 Key Service \u2502 \u2500\u2500\u25b6 \u2502  Activated  \u2502\n\u2502  (api_key)  \u2502     \u2502  (validate) \u2502     \u2502  (running)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key concepts:</p> <ul> <li>Single command activation \u2014 just run <code>pg-collector --config config.yaml</code></li> <li>API key exchanged for JWT tokens \u2014 key is sent once, then tokens handle auth</li> <li>Tier derived from subscription \u2014 your plan determines features and limits</li> <li>Persistent device identity \u2014 survives restarts via local state database</li> <li>Grace period \u2014 continues collecting if the platform is temporarily unreachable</li> </ul>"},{"location":"activation/#getting-an-api-key","title":"Getting an API Key","text":"<ol> <li>Log in to the Burnside Dashboard</li> <li>Navigate to Collector API Keys</li> <li>Click Create Key</li> <li>Copy the generated key</li> </ol> <p>Key format:</p> <pre><code>pgc_{tier}_{32_char_random}\n</code></pre> Prefix Plan <code>pgc_demo_</code> Demo (no subscription required) <code>pgc_starter_</code> Starter <code>pgc_pro_</code> Pro <code>pgc_business_</code> Business <code>pgc_enterprise_</code> Enterprise <p>Tip</p> <p>You can use the same API key across multiple collector instances. Each collector automatically registers with a unique identity.</p>"},{"location":"activation/#minimal-configuration","title":"Minimal Configuration","text":"<p>Only the API key and a database connection are required. Everything else is derived from the platform:</p> <pre><code># /etc/pg-collector/config.yaml\napi_key: \"${PG_COLLECTOR_API_KEY}\"\n\ndatabases:\n  - name: \"Production Primary\"\n    postgres:\n      conn_string: \"postgres://pgcollector@host:5432/db?sslmode=verify-full\"\n      auth_method: cert\n      tls:\n        mode: verify-full\n        ca_file: /etc/pg-collector/certs/ca.crt\n        cert_file: /etc/pg-collector/certs/client.crt\n        key_file: /etc/pg-collector/certs/client.key\n</code></pre> <p>Derived automatically from the platform after activation:</p> <ul> <li>Device identity \u2014 generated on first activation</li> <li>Tier and features \u2014 from your subscription</li> <li>Output destination and limits \u2014 from tier configuration</li> </ul> <p>See Configuration Guide for the full reference.</p>"},{"location":"activation/#first-run","title":"First Run","text":"<p>Activation happens automatically on the first run:</p> <pre><code>export PG_COLLECTOR_API_KEY=\"pgc_pro_abc123...\"\npg-collector --config /etc/pg-collector/config.yaml\n</code></pre> <p>What happens:</p> <ol> <li>Generates a unique device identity</li> <li>Sends the API key to the Burnside platform for validation</li> <li>Receives JWT tokens and tier information</li> <li>Stores device state locally (survives restarts)</li> <li>Begins collecting metrics</li> </ol> <p>On subsequent runs:</p> <ul> <li>Loads state from local storage</li> <li>Uses cached tokens (auto-refreshes before expiry)</li> <li>Never sends the API key again \u2014 only JWT tokens are used after activation</li> </ul>"},{"location":"activation/#device-lifecycle","title":"Device Lifecycle","text":"<pre><code>                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502  UNPROVISIONED   \u2502\n                    \u2502  (first run)     \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502 activate with API key\n                             \u25bc\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502     ACTIVE       \u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502          \u2502  (online, synced) \u2502          \u2502\n        \u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n        \u2502                   \u2502                     \u2502\n        \u2502 subscription      \u2502 platform            \u2502 reconnect +\n        \u2502 cancelled         \u2502 unreachable         \u2502 sync success\n        \u2502                   \u25bc                     \u2502\n        \u2502          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n        \u2502          \u2502      GRACE       \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502          \u2502 (offline, cached) \u2502\n        \u2502          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502                   \u2502 grace period expires\n        \u2502                   \u25bc\n        \u2502          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502     STOPPED      \u2502\n                   \u2502 (no collection)  \u2502\n                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> State Description Collecting? UNPROVISIONED First run, no activation yet No ACTIVE Online, tokens valid, syncing with platform Yes GRACE Platform unreachable, using cached configuration Yes STOPPED Grace period expired or subscription cancelled No"},{"location":"activation/#grace-period","title":"Grace Period","text":"<p>When the Burnside platform is temporarily unreachable, the collector enters grace mode:</p> <ol> <li>Continues collecting metrics using cached configuration</li> <li>Buffers data locally (memory + disk)</li> <li>Retries the platform connection periodically</li> <li>If reconnected within the grace period \u2014 resumes normal operation and flushes buffered data</li> <li>If the grace period expires \u2014 stops collecting until connectivity is restored</li> </ol> <p>Grace period duration depends on your subscription plan. See Subscription Plans for details.</p>"},{"location":"activation/#multi-collector-fleet","title":"Multi-Collector Fleet","text":""},{"location":"activation/#same-api-key-unique-collectors","title":"Same API Key, Unique Collectors","text":"<p>All collectors in a fleet can use the same API key. Each collector automatically registers with a unique identity:</p> <pre><code># Same config deployed to all collectors\napi_key: \"${PG_COLLECTOR_API_KEY}\"  # Same key for all\n\n# Each collector monitors its local database\ndatabases:\n  - name: \"${HOSTNAME}-db\"          # Unique per host\n    postgres:\n      conn_string: \"postgres://pgcollector@localhost:5432/db\"\n</code></pre>"},{"location":"activation/#dashboard-view","title":"Dashboard View","text":"<p>Manage all collectors from the Burnside Dashboard:</p> <pre><code>Customer Account (Pro plan)\n\u2514\u2500\u2500 API Key: pgc_pro_xxx\n    \u251c\u2500\u2500 collector-1 (prod-db-1) \u2014 2 DBs \u2014 Last sync: 5m ago\n    \u251c\u2500\u2500 collector-2 (prod-db-2) \u2014 3 DBs \u2014 Last sync: 2m ago\n    \u2514\u2500\u2500 collector-3 (staging)   \u2014 1 DB  \u2014 Last sync: 1m ago\n</code></pre> <ul> <li>Revoke individual collectors without affecting others</li> <li>Track usage per collector for monitoring and billing</li> <li>Send commands to specific collectors (config updates, restart)</li> </ul>"},{"location":"activation/#cli-commands","title":"CLI Commands","text":"Command Purpose <code>pg-collector --config config.yaml</code> Start collector (activates on first run) <code>pg-collector --status</code> Check running status, tier, and last sync time <code>pg-collector --deactivate</code> Remove local activation state (re-activates on next run) <code>pg-collector --check-config --config config.yaml</code> Validate configuration without starting <p>See CLI Reference for the full command reference.</p>"},{"location":"activation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"activation/#no-activation-found","title":"\"No activation found\"","text":"<pre><code>activation failed: no state.db found\n</code></pre> <p>Solution: Ensure your API key is set in the config file or environment variable, then start the collector.</p>"},{"location":"activation/#api-key-mismatch","title":"\"API key mismatch\"","text":"<pre><code>activation failed: API key hash mismatch\n</code></pre> <p>Solution: The API key in your config differs from the one used to activate. Run <code>pg-collector --deactivate</code> to reset, then restart with the correct key.</p>"},{"location":"activation/#grace-period-expired","title":"\"Grace period expired\"","text":"<pre><code>device stopped: grace period expired\n</code></pre> <p>Solution:</p> <ol> <li>Check network connectivity to the Burnside platform</li> <li>Run <code>pg-collector --deactivate</code></li> <li>Restart the collector to re-activate</li> </ol>"},{"location":"activation/#key-revoked","title":"\"Key revoked\"","text":"<pre><code>device stopped: key revoked\n</code></pre> <p>Solution: Generate a new API key in the Dashboard, update your config, run <code>pg-collector --deactivate</code>, and restart.</p>"},{"location":"activation/#security","title":"Security","text":"<ul> <li>API key is only sent once during activation, over HTTPS</li> <li>API key hash is stored locally as SHA-256 \u2014 the plaintext key is not retained</li> <li>JWT tokens are short-lived (1 hour) and auto-rotated before expiry</li> <li>Local state is protected by file permissions (mode 600)</li> <li>No secrets in logs \u2014 tokens and keys are redacted from all log output</li> </ul>"},{"location":"activation/#related-documentation","title":"Related Documentation","text":"<ul> <li>Subscription Plans \u2014 Compare plans and grace periods</li> <li>Architecture Overview \u2014 How PG Collector works</li> <li>Configuration Guide \u2014 Full configuration reference</li> <li>Security Guide \u2014 Authentication methods and TLS setup</li> </ul>"},{"location":"architecture/","title":"Architecture Overview","text":"<p>How PG Collector works \u2014 from data collection to AI-powered predictions.</p>"},{"location":"architecture/#how-it-works","title":"How It Works","text":"<p>PG Collector is a lightweight agent that runs in your environment alongside PostgreSQL. It collects database telemetry and streams it to the Burnside platform for AI-powered analysis and prediction.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Your Environment                            \u2502\n\u2502                                                                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502  \u2502   PostgreSQL    \u2502         \u2502   PG Collector              \u2502       \u2502\n\u2502  \u2502                 \u2502\u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502   (single binary)           \u2502       \u2502\n\u2502  \u2502  RDS / Aurora / \u2502  query  \u2502                             \u2502       \u2502\n\u2502  \u2502  Cloud SQL /    \u2502         \u2502  - Queries pg_stat_* views  \u2502       \u2502\n\u2502  \u2502  Self-hosted    \u2502         \u2502  - Buffers data locally     \u2502       \u2502\n\u2502  \u2502                 \u2502         \u2502  - Streams to Burnside      \u2502       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n\u2502                                             \u2502                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                              \u2502 HTTPS (port 443)\n                                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                       Burnside Platform                             \u2502\n\u2502                                                                     \u2502\n\u2502   Ingestion \u2192 Storage \u2192 Feature Extraction \u2192 AI/ML \u2192 Predictions   \u2502\n\u2502                                                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key properties:</p> <ul> <li>Single binary \u2014 no JVM, no Python runtime, no external dependencies</li> <li>Read-only \u2014 only queries PostgreSQL system views, never modifies your data</li> <li>Low resource \u2014 minimal RAM and CPU footprint, max 2 PostgreSQL connections, timeout-protected queries</li> <li>Resilient \u2014 local buffering survives network outages with zero data loss</li> </ul>"},{"location":"architecture/#data-flow","title":"Data Flow","text":"<pre><code>PostgreSQL \u2500\u2500\u25b6 Scheduler \u2500\u2500\u25b6 Samplers \u2500\u2500\u25b6 Local Buffer \u2500\u2500\u25b6 Cloud Streaming\n</code></pre> <ol> <li>Scheduler triggers each sampler at its configured interval</li> <li>Samplers query PostgreSQL system views (<code>pg_stat_activity</code>, <code>pg_stat_database</code>, etc.)</li> <li>Local Buffer holds samples in memory with automatic disk overflow for resilience</li> <li>Output sends batched data to the configured destination</li> </ol> <p>When a network outage occurs, data accumulates in the local buffer and drains automatically when connectivity is restored.</p>"},{"location":"architecture/#what-we-collect","title":"What We Collect","text":"<p>PG Collector includes 12 PostgreSQL metric samplers in two groups. Which samplers run depends on your subscription plan.</p>"},{"location":"architecture/#core-samplers","title":"Core Samplers","text":"Sampler PostgreSQL View What You Learn activity <code>pg_stat_activity</code> Active sessions, wait events, blocked queries database <code>pg_stat_database</code> Transaction rates, cache hit ratios, deadlocks statements <code>pg_stat_statements</code> Slow queries, execution plans, call counts bgwriter <code>pg_stat_bgwriter</code> Checkpoint frequency, buffer write pressure replication <code>pg_stat_replication</code> Replication lag (time and bytes), sync state vacuum <code>pg_stat_user_tables</code> Dead tuples, vacuum progress, wraparound risk"},{"location":"architecture/#extended-samplers","title":"Extended Samplers","text":"Sampler PostgreSQL View What You Learn locks <code>pg_locks</code> Lock contention, blocking chains, deadlock risk wal <code>pg_stat_wal</code> WAL generation rate, archiver status slots <code>pg_replication_slots</code> Replication slot lag, inactive slots wal_receiver <code>pg_stat_wal_receiver</code> Standby receive lag statio <code>pg_statio_user_tables</code> Table and index I/O statistics bloat <code>pg_class</code> Table and index bloat estimation <p>See Subscription Plans for sampler availability by plan.</p>"},{"location":"architecture/#deployment-scenarios","title":"Deployment Scenarios","text":""},{"location":"architecture/#bare-metal-vm-most-common","title":"Bare Metal / VM (Most Common)","text":"<p>A VM or bare metal server with network access to PostgreSQL. This is the simplest and most common deployment.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     Your Infrastructure                              \u2502\n\u2502                                                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502   PostgreSQL    \u2502   TCP/5432   \u2502     Monitoring VM            \u2502   \u2502\n\u2502  \u2502                 \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502                              \u2502   \u2502\n\u2502  \u2502  - RDS/Aurora   \u2502              \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502   \u2502\n\u2502  \u2502  - Cloud SQL    \u2502              \u2502  \u2502    pg-collector         \u2502  \u2502   \u2502\n\u2502  \u2502  - Self-hosted  \u2502              \u2502  \u2502    (single binary)      \u2502  \u2502   \u2502\n\u2502  \u2502  - On-prem      \u2502              \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502              \u2502               \u2502   \u2502\n\u2502                                   \u2502              \u2502 HTTPS/443     \u2502   \u2502\n\u2502                                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                  \u2502                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                   \u25bc\n                                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                    \u2502   Burnside Platform         \u2502\n                                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Requirements: Any Linux/macOS machine with network access to PostgreSQL and outbound HTTPS.</p>"},{"location":"architecture/#same-host-as-postgresql","title":"Same Host as PostgreSQL","text":"<p>Run the collector directly on the PostgreSQL server \u2014 simplest network setup.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         PostgreSQL Server               \u2502\n\u2502                                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502   PostgreSQL    \u2502  \u2502 pg-collector \u2502 \u2502\n\u2502  \u2502   (localhost)   \u2502\u25c4\u2500\u2502              \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                              \u2502         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                               \u2502 HTTPS/443\n                               \u25bc\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502  Burnside Platform  \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>No network configuration needed for the PostgreSQL connection. Not recommended for high-load production databases since it shares server resources.</p>"},{"location":"architecture/#docker-container","title":"Docker / Container","text":"<p>Run as a container with network access to PostgreSQL:</p> <pre><code>docker run -d \\\n  --name pg-collector \\\n  -e PG_CONN_STRING=\"postgres://pgcollector@db-host:5432/postgres?sslmode=verify-full\" \\\n  -e API_KEY=\"pgc_pro_xxx\" \\\n  -v /var/lib/pg-collector:/var/lib/pg-collector \\\n  burnside/pg-collector:latest\n</code></pre> <p>Network options: <code>--network host</code> (simplest), <code>--network bridge</code> (ensure PostgreSQL is reachable), or Docker Compose with service names.</p>"},{"location":"architecture/#cloud-vpc-aws-gcp-azure","title":"Cloud VPC (AWS / GCP / Azure)","text":"<p>For managed databases (RDS, Cloud SQL, Azure Database), deploy the collector in the same VPC/VNET:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Your VPC                                     \u2502\n\u2502                                                                      \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502 RDS / Aurora /  \u2502  Private IP  \u2502  EC2 / GCE / Azure VM       \u2502   \u2502\n\u2502  \u2502 Cloud SQL       \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502  (pg-collector)              \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                  \u2502                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                   \u2502 NAT Gateway\n                                                   \u25bc (outbound only)\n                                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                    \u2502   Burnside Platform         \u2502\n                                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Cloud Database Auth Method AWS RDS / Aurora IAM Auth (<code>auth_method: aws_iam</code>) GCP Cloud SQL IAM Auth via Cloud SQL Auth Proxy Azure Azure Database AAD Auth <p>See AWS Setup and GCP Setup for cloud-specific guides.</p>"},{"location":"architecture/#kubernetes","title":"Kubernetes","text":"<p>Deploy as a Deployment with secrets for credentials:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pg-collector\nspec:\n  replicas: 1\n  template:\n    spec:\n      containers:\n      - name: pg-collector\n        image: burnside/pg-collector:latest\n        env:\n        - name: PG_CONN_STRING\n          valueFrom:\n            secretKeyRef:\n              name: pg-credentials\n              key: conn_string\n        - name: API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: burnside-api\n              key: api_key\n        resources:\n          requests:\n            memory: \"64Mi\"\n            cpu: \"100m\"\n          limits:\n            memory: \"128Mi\"\n            cpu: \"250m\"\n</code></pre>"},{"location":"architecture/#resilience","title":"Resilience","text":"<p>PG Collector is designed to never lose data, even during outages.</p>"},{"location":"architecture/#two-tier-buffering","title":"Two-Tier Buffering","text":"<ol> <li>Memory buffer \u2014 holds recent samples in memory for fast access</li> <li>Disk buffer \u2014 when the memory buffer is full, samples overflow to persistent storage on disk</li> <li>Automatic drain \u2014 when the output destination reconnects, the disk buffer drains automatically in order</li> </ol>"},{"location":"architecture/#grace-period","title":"Grace Period","text":"<p>If the Burnside platform is unreachable, the collector enters grace mode and continues collecting metrics using its cached configuration. If connectivity is restored within the grace period, buffered data is flushed and normal operation resumes. See Subscription Plans for grace period by plan.</p>"},{"location":"architecture/#circuit-breakers","title":"Circuit Breakers","text":"<p>All external connections are protected by circuit breakers. When failures exceed a threshold, the circuit opens and the collector stops attempting that connection. The circuit automatically resets after a timeout, preventing cascade failures and allowing recovery.</p>"},{"location":"architecture/#resource-requirements","title":"Resource Requirements","text":"Resource Minimum Recommended CPU 0.1 vCPU 0.25 vCPU Memory 64 MB 128 MB Disk 100 MB 500 MB Network Outbound HTTPS (port 443) \u2014"},{"location":"architecture/#network-requirements","title":"Network Requirements","text":"Connection Direction Port Required Collector to PostgreSQL Outbound 5432 (or custom) Yes Collector to Burnside Platform Outbound 443 (HTTPS) Yes (except local-only demo mode) Health endpoints Inbound 8080 (configurable) Optional (for monitoring) <p>Note</p> <p>PG Collector requires no inbound ports for normal operation. Health endpoints on port 8080 are optional and only needed if you want to integrate with load balancers, Kubernetes probes, or Prometheus scraping.</p>"},{"location":"architecture/#related-documentation","title":"Related Documentation","text":"<ul> <li>Subscription Plans \u2014 Compare plans and features</li> <li>Device Activation \u2014 How collectors activate and authenticate</li> <li>Configuration Guide \u2014 Full configuration reference</li> <li>Monitoring \u2014 Health endpoints and Prometheus metrics</li> </ul>"},{"location":"aws-setup/","title":"AWS Setup Guide","text":"<p>Deploy PG Collector with Amazon RDS and Aurora using IAM authentication.</p>"},{"location":"aws-setup/#overview","title":"Overview","text":"<p>AWS IAM database authentication allows you to connect to RDS/Aurora without passwords. The collector uses temporary tokens generated from IAM credentials.</p> <p>Benefits: - No password management - Automatic credential rotation - Fine-grained IAM policies - CloudTrail audit logging</p>"},{"location":"aws-setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Amazon RDS or Aurora PostgreSQL instance</li> <li>IAM permissions to create roles and policies</li> <li>PG Collector installed on EC2, ECS, or Lambda</li> </ul>"},{"location":"aws-setup/#step-1-enable-iam-authentication-on-rds","title":"Step 1: Enable IAM Authentication on RDS","text":""},{"location":"aws-setup/#console","title":"Console","text":"<ol> <li>Go to RDS Console \u2192 Select your instance</li> <li>Click Modify</li> <li>Under Database authentication, select Password and IAM database authentication</li> <li>Click Continue \u2192 Apply immediately</li> </ol>"},{"location":"aws-setup/#cli","title":"CLI","text":"<pre><code>aws rds modify-db-instance \\\n  --db-instance-identifier mydb \\\n  --enable-iam-database-authentication \\\n  --apply-immediately\n</code></pre>"},{"location":"aws-setup/#step-2-create-database-user","title":"Step 2: Create Database User","text":"<p>Connect to your database:</p> <pre><code>-- Create user with rds_iam role\nCREATE USER pgcollector WITH LOGIN;\nGRANT rds_iam TO pgcollector;\n\n-- Grant monitoring permissions\nGRANT pg_monitor TO pgcollector;\n</code></pre>"},{"location":"aws-setup/#step-3-create-iam-policy","title":"Step 3: Create IAM Policy","text":"<pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": \"rds-db:connect\",\n      \"Resource\": \"arn:aws:rds-db:REGION:ACCOUNT_ID:dbuser:DBI_RESOURCE_ID/pgcollector\"\n    }\n  ]\n}\n</code></pre> <p>Replace: - <code>REGION</code> with your region (e.g., <code>us-east-1</code>) - <code>ACCOUNT_ID</code> with your AWS account ID - <code>DBI_RESOURCE_ID</code> with your database resource ID (found in RDS Console \u2192 Configuration)</p>"},{"location":"aws-setup/#step-4-create-iam-role","title":"Step 4: Create IAM Role","text":""},{"location":"aws-setup/#for-ec2","title":"For EC2","text":"<pre><code># Create role\naws iam create-role \\\n  --role-name pg-collector-role \\\n  --assume-role-policy-document '{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [{\n      \"Effect\": \"Allow\",\n      \"Principal\": {\"Service\": \"ec2.amazonaws.com\"},\n      \"Action\": \"sts:AssumeRole\"\n    }]\n  }'\n\n# Attach policy\naws iam attach-role-policy \\\n  --role-name pg-collector-role \\\n  --policy-arn arn:aws:iam::ACCOUNT_ID:policy/pg-collector-rds-connect\n\n# Create instance profile and attach to EC2\naws iam create-instance-profile --instance-profile-name pg-collector-profile\naws iam add-role-to-instance-profile \\\n  --instance-profile-name pg-collector-profile \\\n  --role-name pg-collector-role\n</code></pre>"},{"location":"aws-setup/#for-ecs","title":"For ECS","text":"<p>Add the policy to your ECS task role.</p>"},{"location":"aws-setup/#step-5-download-rds-ca-certificate","title":"Step 5: Download RDS CA Certificate","text":"<pre><code>curl -o /etc/pg-collector/certs/rds-ca-bundle.pem \\\n  https://truststore.pki.rds.amazonaws.com/global/global-bundle.pem\n\nsudo chmod 644 /etc/pg-collector/certs/rds-ca-bundle.pem\n</code></pre>"},{"location":"aws-setup/#step-6-configure-pg-collector","title":"Step 6: Configure PG Collector","text":"<pre><code>api_key: \"${API_KEY}\"\n\ndatabases:\n  - name: RDS Production\n    postgres:\n  conn_string: \"postgres://pgcollector@mydb.xxxxx.us-east-1.rds.amazonaws.com:5432/postgres?sslmode=verify-full\"\n  auth_method: aws_iam\n  aws_iam:\n    enabled: true\n    region: \"us-east-1\"\n  tls:\n    mode: verify-full\n    ca_file: /etc/pg-collector/certs/rds-ca-bundle.pem\n</code></pre> <p>See Configuration Guide for all options.</p>"},{"location":"aws-setup/#step-7-verify-configuration","title":"Step 7: Verify Configuration","text":"<pre><code># Validate config syntax\npg-collector --check-config --config /etc/pg-collector/config.yaml\n\n# Test by running (Ctrl+C to stop after verifying connection)\npg-collector --config /etc/pg-collector/config.yaml\n</code></pre>"},{"location":"aws-setup/#aurora-notes","title":"Aurora Notes","text":""},{"location":"aws-setup/#use-reader-endpoint","title":"Use Reader Endpoint","text":"<p>Use the reader endpoint for monitoring to avoid impacting writes:</p> <pre><code>postgres:\n  conn_string: \"postgres://pgcollector@mydb.cluster-ro-xxxxx.us-east-1.rds.amazonaws.com:5432/postgres?sslmode=verify-full\"\n</code></pre>"},{"location":"aws-setup/#troubleshooting","title":"Troubleshooting","text":"Issue Cause Solution PAM authentication failed IAM auth not enabled Enable on RDS instance Access denied Policy resource ARN wrong Verify region, account ID, DBI resource ID Connection timeout Security group Allow inbound port 5432"},{"location":"aws-setup/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Use private subnets for collector instances</li> <li>Restrict IAM policy to specific database</li> <li>Enable CloudTrail for audit logging</li> <li>Use reader endpoint for Aurora clusters</li> </ol>"},{"location":"cli-reference/","title":"CLI Reference","text":"<p>Command-line options for PG Collector.</p>"},{"location":"cli-reference/#usage","title":"Usage","text":"<pre><code>pg-collector --config /etc/pg-collector/config.yaml\n</code></pre>"},{"location":"cli-reference/#options","title":"Options","text":"Option Description Default <code>--config</code> Path to configuration file <code>/etc/pg-collector/config.yaml</code> <code>--check-config</code> Validate configuration and exit - <code>--status</code> Check if collector is running - <code>--deactivate</code> Remove activation and exit - <code>--state-db</code> Path to device state database <code>/var/lib/pg-collector/state.db</code> <code>--pid-file</code> Path to PID file <code>/var/run/pg-collector.pid</code> <code>--version</code> Print version and exit - <code>--version-json</code> Print version as JSON -"},{"location":"cli-reference/#examples","title":"Examples","text":""},{"location":"cli-reference/#start-collector","title":"Start Collector","text":"<pre><code>pg-collector --config /etc/pg-collector/config.yaml\n</code></pre> <p>On first run, automatically activates using <code>api_key</code> from config file.</p>"},{"location":"cli-reference/#validate-configuration","title":"Validate Configuration","text":"<pre><code>pg-collector --check-config --config /etc/pg-collector/config.yaml\n</code></pre> <p>Output: <pre><code>Configuration file /etc/pg-collector/config.yaml is valid\n  Plan:       pro\n  Databases:  1\n</code></pre></p>"},{"location":"cli-reference/#check-status","title":"Check Status","text":"<pre><code>pg-collector --status\n</code></pre> <p>Output: <pre><code>pg-collector is running (PID 12345)\n  Version: 1.0.0\n  Commit:  abc1234\n</code></pre></p>"},{"location":"cli-reference/#print-version","title":"Print Version","text":"<pre><code>pg-collector --version\n</code></pre> <p>Output: <pre><code>pg-collector 1.0.0 (abc1234)\n</code></pre></p>"},{"location":"cli-reference/#deactivate","title":"Deactivate","text":"<pre><code>pg-collector --deactivate\n</code></pre> <p>Removes stored state. Next run will re-activate using <code>api_key</code> from config.</p>"},{"location":"cli-reference/#exit-codes","title":"Exit Codes","text":"Code Meaning 0 Success 1 Error"},{"location":"cli-reference/#environment-variables","title":"Environment Variables","text":"<p>Override configuration via environment:</p> Variable Description <code>PG_COLLECTOR_LOG_LEVEL</code> Log level: debug, info, warn, error <code>PG_COLLECTOR_LOG_FORMAT</code> Log format: json, console"},{"location":"cli-reference/#environment-variable-expansion-in-config","title":"Environment Variable Expansion in Config","text":"<p>Use <code>${VAR}</code> syntax in configuration files:</p> <pre><code>api_key: \"${PG_COLLECTOR_API_KEY}\"\n# Plan is derived automatically from activation\n</code></pre> <p>Supported syntax: - <code>${VAR}</code> - Required variable (fails if not set) - <code>${VAR:-default}</code> - Use default if not set</p>"},{"location":"cli-reference/#signals","title":"Signals","text":"Signal Action <code>SIGTERM</code> Graceful shutdown <code>SIGINT</code> Graceful shutdown"},{"location":"cli-reference/#graceful-shutdown","title":"Graceful Shutdown","text":"<p>On shutdown signal: 1. Stop schedulers (no new samples) 2. Flush buffers 3. Close database connections 4. Exit</p>"},{"location":"configuration/","title":"Configuration Guide","text":"<p>Complete reference for PG Collector configuration.</p>"},{"location":"configuration/#configuration-file","title":"Configuration File","text":"<p>Default location: <code>/etc/pg-collector/config.yaml</code></p> <p>Override with: <code>pg-collector --config /path/to/config.yaml</code></p>"},{"location":"configuration/#minimal-configuration","title":"Minimal Configuration","text":"<p>The simplest production configuration \u2014 just your API key and a database connection:</p> <pre><code>api_key: \"${API_KEY}\"\n\ndatabases:\n  - name: Production\n    postgres:\n      conn_string: \"postgres://pgcollector@your-db:5432/postgres?sslmode=verify-full\"\n      auth_method: cert\n      tls:\n        mode: verify-full\n        ca_file: /etc/pg-collector/certs/ca.crt\n        cert_file: /etc/pg-collector/certs/client.crt\n        key_file: /etc/pg-collector/certs/client.key\n</code></pre> <p>Everything else \u2014 tier, features, output destination, sampling intervals \u2014 is derived automatically from your subscription after device activation.</p>"},{"location":"configuration/#full-configuration-reference","title":"Full Configuration Reference","text":"<pre><code># =============================================================================\n# ACTIVATION (Required for production)\n# =============================================================================\n\n# API key from admin console (required)\n# On first run, collector activates using this key\napi_key: \"${API_KEY}\"\n\n# =============================================================================\n# DATABASES (Required)\n# =============================================================================\n\ndatabases:\n  - name: \"Production\"\n\n    # Optional: Filter which samplers run for this database\n    # If omitted, all tier-allowed samplers are enabled\n    # samplers: [activity, database, statements, bgwriter, replication, vacuum]\n\n    postgres:\n      conn_string: \"postgres://pgcollector@your-db:5432/postgres?sslmode=verify-full\"\n      auth_method: cert\n      query_timeout: 5s\n      tls:\n        mode: verify-full\n        ca_file: /etc/pg-collector/certs/ca.crt\n        cert_file: /etc/pg-collector/certs/client.crt\n        key_file: /etc/pg-collector/certs/client.key\n\n# =============================================================================\n# SAMPLING INTERVALS\n# =============================================================================\n\nsampling:\n  # Enable/disable samplers\n  enabled:\n    activity: true\n    database: true\n    statements: true\n    bgwriter: true\n    replication: true\n    vacuum: true\n    locks: false       # Extended, disabled by default\n    wal: false\n    slots: false\n    wal_receiver: false\n    statio: false\n    bloat: false\n\n  # Sampling intervals (plan defaults applied automatically)\n  # You can override intervals here, but they will be clamped to your plan's\n  # minimum interval. For example, setting activity: 5s on a Starter plan\n  # will use the Starter minimum instead.\n  activity: 10s\n  database: 30s\n  statements: 60s\n\n# =============================================================================\n# SAMPLER REFERENCE\n# =============================================================================\n#\n# Core (Default enabled):\n#   activity    - Active sessions, wait events (pg_stat_activity)\n#   database    - Transaction rates, cache hits (pg_stat_database)\n#   statements  - Query performance metrics (pg_stat_statements)\n#   bgwriter    - Checkpoint and buffer stats (pg_stat_bgwriter)\n#   replication - Replication lag and sync state (pg_stat_replication)\n#   vacuum      - Dead tuples, vacuum progress (pg_stat_user_tables)\n#\n# Extended (Default disabled):\n#   locks        - Lock contention analysis (pg_locks)\n#   wal          - WAL generation stats (pg_stat_wal, PG 14+)\n#   slots        - Replication slot lag (pg_replication_slots)\n#   wal_receiver - Standby receive lag (pg_stat_wal_receiver)\n#   statio       - Table I/O statistics (pg_statio_user_tables)\n#   bloat        - Table/index bloat estimation\n\n# =============================================================================\n# HTTP ENDPOINTS\n# =============================================================================\n\nhttp:\n  address: \":8080\"\n  read_timeout: 5s\n  write_timeout: 10s\n\n# =============================================================================\n# LOGGING\n# =============================================================================\n\nlog:\n  level: info      # debug, info, warn, error\n  format: json     # json, console\n\n# =============================================================================\n# SECURITY\n# =============================================================================\n\nsecurity:\n  # Query masking: none, basic, full, custom\n  query_masking_level: basic\n\n  # PII detection (Business/Enterprise only)\n  pii_detection: false\n\n  # Audit logging (Business/Enterprise only)\n  audit_logging: false\n  audit_log_path: /var/log/pg-collector/audit.log\n\n  # Custom masking patterns (Enterprise only)\n  masking_patterns:\n    - \"password\"\n    - \"secret\"\n    - \"token\"\n</code></pre>"},{"location":"configuration/#plan-based-defaults","title":"Plan-Based Defaults","text":"<p>Features and limits vary by subscription plan. The collector automatically applies the correct defaults based on your plan after device activation.</p> Feature Demo Starter Pro Business Enterprise Database limit 1 1 Multiple Many Unlimited Sampling frequency Basic Standard Fast Faster Real-time Query masking Basic Basic Custom Custom Custom PII detection Basic Basic Basic Full Full Audit logging \u2014 \u2014 \u2014 Yes Yes <p>See Subscription Plans for the full comparison including sampler availability and security features.</p> <p>Plan Minimums</p> <p>If you set a sampling interval lower than your plan allows, the collector will use the plan minimum instead.</p>"},{"location":"configuration/#environment-variables","title":"Environment Variables","text":"<p>PG Collector supports environment variable expansion in all configuration values. Use <code>${VAR}</code> for required variables and <code>${VAR:-default}</code> for optional ones with fallback values.</p>"},{"location":"configuration/#supported-variables","title":"Supported Variables","text":"<p>Authentication:</p> Variable Description Default <code>API_KEY</code> API key for activation (required) <p>PostgreSQL Connection:</p> Variable Description Default <code>PG_CONN_STRING</code> Full connection string (required) <code>PG_HOST</code> PostgreSQL host <code>localhost</code> <code>PG_PORT</code> PostgreSQL port <code>5432</code> <code>PG_USER</code> PostgreSQL username \u2014 <code>PG_AUTH_METHOD</code> Auth method (<code>cert</code>, <code>aws_iam</code>, <code>gcp_iam</code>) <code>cert</code> <code>PG_TLS_MODE</code> TLS mode <code>verify-full</code> <code>PG_CA_FILE</code> CA certificate path \u2014 <code>PG_CERT_FILE</code> Client certificate path \u2014 <code>PG_KEY_FILE</code> Client key path \u2014 <p>Logging and HTTP:</p> Variable Description Default <code>LOG_LEVEL</code> Log level (<code>debug</code>, <code>info</code>, <code>warn</code>, <code>error</code>) <code>info</code> <code>LOG_FORMAT</code> Log format (<code>json</code>, <code>console</code>) <code>json</code> <code>HTTP_ADDRESS</code> Health endpoint bind address <code>:8080</code>"},{"location":"configuration/#usage-in-config","title":"Usage in Config","text":"<pre><code>api_key: \"${API_KEY}\"\n\ndatabases:\n  - name: Production\n    postgres:\n      conn_string: \"postgres://${PG_USER}@${PG_HOST}:${PG_PORT:-5432}/${PG_DB}?sslmode=verify-full\"\n</code></pre>"},{"location":"configuration/#kubernetes-secrets-example","title":"Kubernetes Secrets Example","text":"<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: pg-collector-secrets\ntype: Opaque\nstringData:\n  API_KEY: \"pgc_pro_abc123...\"\n  PG_CONN_STRING: \"postgres://pgcollector@db:5432/postgres\"\n---\napiVersion: apps/v1\nkind: Deployment\nspec:\n  template:\n    spec:\n      containers:\n        - name: pg-collector\n          envFrom:\n            - secretRef:\n                name: pg-collector-secrets\n</code></pre>"},{"location":"configuration/#docker-compose-example","title":"Docker Compose Example","text":"<pre><code>services:\n  pg-collector:\n    image: burnside/pg-collector:latest\n    environment:\n      - API_KEY=${API_KEY}\n      - PG_CONN_STRING=postgres://pgcollector@db:5432/postgres\n    env_file:\n      - .env\n</code></pre>"},{"location":"configuration/#security-best-practices","title":"Security Best Practices","text":"<ul> <li>Never hardcode secrets in config files \u2014 always use <code>${VAR}</code> references</li> <li>Use secret managers in production \u2014 AWS Secrets Manager, GCP Secret Manager, HashiCorp Vault, or Kubernetes Secrets</li> <li>Restrict access to <code>.env</code> files \u2014 <code>chmod 600 .env</code></li> <li>Validate at startup \u2014 use <code>pg-collector --check-config</code> to verify all variables resolve before running</li> </ul>"},{"location":"configuration/#validation","title":"Validation","text":"<pre><code>pg-collector --check-config --config /etc/pg-collector/config.yaml\n</code></pre>"},{"location":"configuration/#demo-mode","title":"Demo Mode","text":"<p>For quick evaluation without API key:</p> <pre><code># Demo mode uses password auth (not for production)\ndatabases:\n  - name: local\n    postgres:\n      conn_string: \"postgres://user:pass@localhost:5432/postgres\"\n      auth_method: password\n\nlocal:\n  enabled: true\n  path: ./output\n</code></pre> <p>Note: Password auth only works in demo builds (<code>BUILD_MODE=demo</code>).</p>"},{"location":"configuration/#multiple-databases","title":"Multiple Databases","text":"<pre><code>databases:\n  - name: Production Primary\n    postgres:\n      conn_string: \"postgres://pgcollector@db1:5432/postgres?sslmode=verify-full\"\n\n  - name: Production Replica\n    postgres:\n      conn_string: \"postgres://pgcollector@db2:5432/postgres?sslmode=verify-full\"\n</code></pre>"},{"location":"configuration/#cloud-examples","title":"Cloud Examples","text":""},{"location":"configuration/#aws-rds","title":"AWS RDS","text":"<pre><code>databases:\n  - name: RDS Production\n    postgres:\n      conn_string: \"postgres://pgcollector@mydb.xxx.us-east-1.rds.amazonaws.com:5432/postgres\"\n      auth_method: aws_iam\n      aws_iam:\n        enabled: true\n        region: us-east-1\n      tls:\n        mode: verify-full\n        ca_file: /etc/pg-collector/certs/rds-ca-bundle.pem\n</code></pre>"},{"location":"configuration/#gcp-cloud-sql","title":"GCP Cloud SQL","text":"<pre><code>databases:\n  - name: Cloud SQL Production\n    postgres:\n      conn_string: \"postgres://pgcollector@/postgres?host=/cloudsql/project:region:instance\"\n      auth_method: gcp_iam\n      gcp_iam:\n        enabled: true\n</code></pre>"},{"location":"configuration/#related-documentation","title":"Related Documentation","text":"<ul> <li>Quick Start - Get started quickly</li> <li>Security Guide - TLS and authentication</li> <li>Monitoring - Health endpoints</li> </ul>"},{"location":"faq/","title":"Frequently Asked Questions","text":"<p>Quick answers to common questions.</p>"},{"location":"faq/#general","title":"General","text":""},{"location":"faq/#what-postgresql-versions-are-supported","title":"What PostgreSQL versions are supported?","text":"<p>PostgreSQL 12 and later. Some features (like certain pg_stat views) require newer versions.</p>"},{"location":"faq/#does-pg-collector-impact-database-performance","title":"Does PG Collector impact database performance?","text":"<p>No. PG Collector is designed from the ground up for zero database impact: - Read-only queries with timeout protection - Maximum 2 database connections - Automatic backoff when your database is busy - No locks, no writes, no schema changes</p>"},{"location":"faq/#what-platforms-are-supported","title":"What platforms are supported?","text":"<ul> <li>Linux: x86_64 (amd64), ARM64</li> <li>macOS: Intel, Apple Silicon</li> <li>Windows: x86_64</li> </ul>"},{"location":"faq/#can-i-monitor-multiple-databases","title":"Can I monitor multiple databases?","text":"<p>Run one PG Collector instance per database. Each instance connects to a single PostgreSQL database.</p>"},{"location":"faq/#installation","title":"Installation","text":""},{"location":"faq/#where-is-the-binary-installed","title":"Where is the binary installed?","text":"<p>Default location: <code>/usr/local/bin/pg-collector</code></p>"},{"location":"faq/#where-are-configuration-files","title":"Where are configuration files?","text":"<p>Default location: <code>/etc/pg-collector/config.yaml</code></p>"},{"location":"faq/#where-are-certificates-stored","title":"Where are certificates stored?","text":"<p>Recommended location: <code>/etc/pg-collector/certs/</code></p>"},{"location":"faq/#where-is-the-buffer-stored","title":"Where is the buffer stored?","text":"<p>Default location: <code>/var/lib/pg-collector/buffer.db</code></p>"},{"location":"faq/#authentication","title":"Authentication","text":""},{"location":"faq/#why-isnt-password-authentication-supported-in-production","title":"Why isn't password authentication supported in production?","text":"<p>Security first. Storing passwords in configuration files creates unnecessary risk. Certificate and IAM authentication eliminate password management entirely\u2014no rotation, no exposure in logs, no secrets to protect.</p> <p>Note: Password auth is available in demo builds for evaluation purposes.</p>"},{"location":"faq/#can-i-use-aws-iam-with-self-managed-postgresql","title":"Can I use AWS IAM with self-managed PostgreSQL?","text":"<p>No, AWS IAM authentication only works with Amazon RDS and Aurora.</p>"},{"location":"faq/#my-certificates-expired-what-do-i-do","title":"My certificates expired. What do I do?","text":"<ol> <li>Generate new certificates</li> <li>Update PostgreSQL server if CA changed</li> <li>Update collector with new certificates</li> <li>Restart the collector</li> </ol>"},{"location":"faq/#connectivity","title":"Connectivity","text":""},{"location":"faq/#what-ports-does-pg-collector-use","title":"What ports does PG Collector use?","text":"<ul> <li>Outbound: PostgreSQL port (usually 5432)</li> <li>Outbound: Burnside cloud (HTTPS 443)</li> <li>Inbound: Health endpoint (default 8080)</li> </ul>"},{"location":"faq/#can-i-run-behind-a-proxy","title":"Can I run behind a proxy?","text":"<p>Yes, set standard proxy environment variables: <pre><code>export HTTPS_PROXY=http://proxy:8080\n</code></pre></p>"},{"location":"faq/#what-happens-during-network-outages","title":"What happens during network outages?","text":"<p>Metrics are buffered locally (memory, then disk) and sent when connectivity is restored. No data is lost during temporary outages.</p>"},{"location":"faq/#operations","title":"Operations","text":""},{"location":"faq/#how-do-i-check-if-its-working","title":"How do I check if it's working?","text":"<pre><code># Check health\ncurl http://localhost:8080/health\n\n# Check status\ncurl http://localhost:8080/status\n\n# Check logs\nsudo journalctl -u pg-collector -f\n</code></pre>"},{"location":"faq/#how-do-i-upgrade","title":"How do I upgrade?","text":"<ol> <li>Download new version</li> <li>Stop service: <code>sudo systemctl stop pg-collector</code></li> <li>Replace binary: <code>sudo mv pg-collector /usr/local/bin/</code></li> <li>Start service: <code>sudo systemctl start pg-collector</code></li> </ol>"},{"location":"faq/#how-do-i-change-configuration","title":"How do I change configuration?","text":"<ol> <li>Edit <code>/etc/pg-collector/config.yaml</code></li> <li>Validate: <code>pg-collector --check-config --config /etc/pg-collector/config.yaml</code></li> <li>Restart: <code>sudo systemctl restart pg-collector</code></li> </ol>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"faq/#the-service-keeps-restarting","title":"The service keeps restarting","text":"<p>Check logs for the cause: <pre><code>sudo journalctl -u pg-collector -n 100\n</code></pre></p> <p>Common causes: - Invalid configuration - Cannot connect to PostgreSQL - Certificate issues</p>"},{"location":"faq/#high-memory-usage","title":"High memory usage","text":"<p>Check your buffer configuration: <pre><code>buffers:\n  memory_capacity: 1000  # Number of samples to buffer\n</code></pre></p> <p>Reduce if needed, or check for output issues causing backpressure.</p>"},{"location":"faq/#connection-refused-errors","title":"Connection refused errors","text":"<ol> <li>Check PostgreSQL is running</li> <li>Check firewall allows connection</li> <li>Check pg_hba.conf permits the connection</li> <li>Test with psql directly</li> </ol>"},{"location":"faq/#security","title":"Security","text":""},{"location":"faq/#is-data-encrypted-in-transit","title":"Is data encrypted in transit?","text":"<p>Yes, when using <code>sslmode=verify-full</code> (recommended), all connections are TLS encrypted.</p>"},{"location":"faq/#is-data-encrypted-at-rest","title":"Is data encrypted at rest?","text":"<p>The local buffer is not encrypted. The Burnside cloud encrypts all data at rest.</p>"},{"location":"faq/#what-permissions-does-the-postgresql-user-need","title":"What permissions does the PostgreSQL user need?","text":"<pre><code>GRANT pg_monitor TO pgcollector;\n</code></pre> <p>This provides read-only access to monitoring views.</p>"},{"location":"faq/#support","title":"Support","text":""},{"location":"faq/#where-do-i-report-bugs","title":"Where do I report bugs?","text":"<p>GitHub Issues \u2014 We actively monitor and respond.</p>"},{"location":"faq/#how-do-i-get-commercial-support","title":"How do I get commercial support?","text":"<p>Email support@burnsideproject.ai \u2014 Pro and Enterprise customers get priority response.</p>"},{"location":"faq/#i-have-a-feature-request","title":"I have a feature request","text":"<p>We'd love to hear it! Open a GitHub Issue with the \"enhancement\" label, or email us directly.</p>"},{"location":"faq/#where-is-the-full-documentation","title":"Where is the full documentation?","text":"<p>You're reading it! Also available at github.com/burnside-project/pg-collector/docs</p>"},{"location":"gcp-setup/","title":"GCP Setup Guide","text":"<p>Deploy PG Collector with Google Cloud SQL using IAM authentication.</p>"},{"location":"gcp-setup/#overview","title":"Overview","text":"<p>Cloud SQL IAM authentication allows passwordless connections using Google service accounts.</p> <p>Benefits: - No password management - Automatic credential rotation - IAM-based access control - Cloud Audit Logs integration</p>"},{"location":"gcp-setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Google Cloud SQL PostgreSQL instance</li> <li>IAM permissions to manage service accounts</li> <li>PG Collector installed on GCE, GKE, or Cloud Run</li> </ul>"},{"location":"gcp-setup/#step-1-enable-iam-authentication","title":"Step 1: Enable IAM Authentication","text":""},{"location":"gcp-setup/#console","title":"Console","text":"<ol> <li>Go to Cloud SQL Console \u2192 Select your instance</li> <li>Click Edit</li> <li>Under Connections, enable Cloud SQL IAM authentication</li> <li>Click Save</li> </ol>"},{"location":"gcp-setup/#gcloud-cli","title":"gcloud CLI","text":"<pre><code>gcloud sql instances patch INSTANCE_NAME \\\n  --database-flags cloudsql.iam_authentication=on\n</code></pre>"},{"location":"gcp-setup/#step-2-create-service-account","title":"Step 2: Create Service Account","text":"<pre><code># Create service account\ngcloud iam service-accounts create pg-collector \\\n  --display-name=\"PG Collector Service Account\"\n\n# Note the email\nSA_EMAIL=\"pg-collector@PROJECT_ID.iam.gserviceaccount.com\"\n</code></pre>"},{"location":"gcp-setup/#step-3-grant-permissions","title":"Step 3: Grant Permissions","text":"<pre><code># Grant Cloud SQL Client role\ngcloud projects add-iam-policy-binding PROJECT_ID \\\n  --member=\"serviceAccount:${SA_EMAIL}\" \\\n  --role=\"roles/cloudsql.client\"\n\n# Grant Cloud SQL Instance User role\ngcloud projects add-iam-policy-binding PROJECT_ID \\\n  --member=\"serviceAccount:${SA_EMAIL}\" \\\n  --role=\"roles/cloudsql.instanceUser\"\n</code></pre>"},{"location":"gcp-setup/#step-4-create-database-user","title":"Step 4: Create Database User","text":"<p>Connect to your Cloud SQL instance:</p> <pre><code>-- Create IAM user\nCREATE USER \"pg-collector@PROJECT_ID.iam\" WITH LOGIN;\n\n-- Grant monitoring permissions\nGRANT pg_monitor TO \"pg-collector@PROJECT_ID.iam\";\n</code></pre> <p>Note: Username format must include <code>.iam</code> suffix.</p>"},{"location":"gcp-setup/#step-5-deploy-with-service-account","title":"Step 5: Deploy with Service Account","text":""},{"location":"gcp-setup/#gce-compute-engine","title":"GCE (Compute Engine)","text":"<pre><code>gcloud compute instances create pg-collector-vm \\\n  --service-account=${SA_EMAIL} \\\n  --scopes=https://www.googleapis.com/auth/cloud-platform\n</code></pre>"},{"location":"gcp-setup/#gke-kubernetes","title":"GKE (Kubernetes)","text":"<p>Use Workload Identity:</p> <pre><code>apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: pg-collector\n  annotations:\n    iam.gke.io/gcp-service-account: pg-collector@PROJECT_ID.iam.gserviceaccount.com\n</code></pre>"},{"location":"gcp-setup/#step-6-configure-pg-collector","title":"Step 6: Configure PG Collector","text":""},{"location":"gcp-setup/#with-cloud-sql-proxy-recommended","title":"With Cloud SQL Proxy (Recommended)","text":"<pre><code>api_key: \"${API_KEY}\"\n\ndatabases:\n  - name: Cloud SQL Production\n    postgres:\n  conn_string: \"postgres://pg-collector@PROJECT_ID.iam@/postgres?host=/cloudsql/PROJECT_ID:REGION:INSTANCE_NAME\"\n  auth_method: gcp_iam\n  gcp_iam:\n    enabled: true\n\n# Direct connection config also supported (see below)\n</code></pre> <p>See Configuration Guide for all options.</p>"},{"location":"gcp-setup/#direct-connection","title":"Direct Connection","text":"<pre><code>postgres:\n  conn_string: \"postgres://pg-collector@PROJECT_ID.iam@INSTANCE_IP:5432/postgres?sslmode=verify-full\"\n  auth_method: gcp_iam\n  gcp_iam:\n    enabled: true\n  tls:\n    mode: verify-full\n    ca_file: /etc/pg-collector/certs/server-ca.pem\n</code></pre>"},{"location":"gcp-setup/#step-7-install-cloud-sql-proxy","title":"Step 7: Install Cloud SQL Proxy","text":"<pre><code># Download\ncurl -o /usr/local/bin/cloud-sql-proxy \\\n  https://storage.googleapis.com/cloud-sql-connectors/cloud-sql-proxy/v2.8.0/cloud-sql-proxy.linux.amd64\n\nchmod +x /usr/local/bin/cloud-sql-proxy\n\n# Run\ncloud-sql-proxy PROJECT_ID:REGION:INSTANCE_NAME &amp;\n</code></pre>"},{"location":"gcp-setup/#step-8-verify-configuration","title":"Step 8: Verify Configuration","text":"<pre><code># Validate config syntax\npg-collector --check-config --config /etc/pg-collector/config.yaml\n\n# Test by running (Ctrl+C to stop after verifying connection)\npg-collector --config /etc/pg-collector/config.yaml\n</code></pre>"},{"location":"gcp-setup/#troubleshooting","title":"Troubleshooting","text":"Issue Cause Solution Password authentication failed IAM auth not enabled Enable on Cloud SQL Permission denied Missing IAM role Add <code>cloudsql.instanceUser</code> role Connection refused Proxy not running Start Cloud SQL Proxy"},{"location":"gcp-setup/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Use Cloud SQL Proxy instead of public IP</li> <li>Enable private IP for Cloud SQL</li> <li>Use Workload Identity on GKE</li> <li>Enable Cloud Audit Logs</li> </ol>"},{"location":"installation/","title":"Installation Guide","text":"<p>Get PG Collector running in minutes. Detailed installation instructions for all platforms.</p>"},{"location":"installation/#system-requirements","title":"System Requirements","text":"<ul> <li>OS: Linux (amd64, arm64), macOS (Intel, Apple Silicon), Windows (amd64)</li> <li>PostgreSQL: Version 12 or later</li> <li>Memory: 64MB minimum, 128MB recommended</li> <li>Disk: 100MB for binary + buffer space</li> </ul>"},{"location":"installation/#linux-installation","title":"Linux Installation","text":""},{"location":"installation/#one-line-install","title":"One-Line Install","text":"<pre><code>curl -sSL https://raw.githubusercontent.com/burnside-project/pg-collector/main/scripts/install.sh | sudo bash\n</code></pre> <p>This script: - Detects your architecture - Downloads the latest release - Installs to <code>/usr/local/bin/</code> - Creates system user <code>pg-collector</code> - Sets up directory structure</p>"},{"location":"installation/#manual-installation","title":"Manual Installation","text":"<pre><code># Download (choose your architecture)\ncurl -LO https://github.com/burnside-project/pg-collector/releases/latest/download/pg-collector-linux-amd64.tar.gz\n\n# Extract\ntar -xzf pg-collector-linux-amd64.tar.gz\n\n# Install binary\nsudo mv pg-collector /usr/local/bin/\nsudo chmod +x /usr/local/bin/pg-collector\n\n# Create system user\nsudo useradd --system --no-create-home --shell /sbin/nologin pg-collector\n\n# Create directories\nsudo mkdir -p /etc/pg-collector/certs\nsudo mkdir -p /var/lib/pg-collector\n\n# Set ownership\nsudo chown -R pg-collector:pg-collector /var/lib/pg-collector\n</code></pre>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<pre><code>pg-collector --version\n</code></pre>"},{"location":"installation/#macos-installation","title":"macOS Installation","text":""},{"location":"installation/#intel-mac","title":"Intel Mac","text":"<pre><code>curl -LO https://github.com/burnside-project/pg-collector/releases/latest/download/pg-collector-darwin-amd64.tar.gz\ntar -xzf pg-collector-darwin-amd64.tar.gz\nsudo mv pg-collector /usr/local/bin/\n</code></pre>"},{"location":"installation/#apple-silicon-m1m2m3","title":"Apple Silicon (M1/M2/M3)","text":"<pre><code>curl -LO https://github.com/burnside-project/pg-collector/releases/latest/download/pg-collector-darwin-arm64.tar.gz\ntar -xzf pg-collector-darwin-arm64.tar.gz\nsudo mv pg-collector /usr/local/bin/\n</code></pre>"},{"location":"installation/#directory-setup","title":"Directory Setup","text":"<pre><code>sudo mkdir -p /etc/pg-collector/certs\nsudo mkdir -p /var/lib/pg-collector\n</code></pre>"},{"location":"installation/#windows-installation","title":"Windows Installation","text":""},{"location":"installation/#powershell","title":"PowerShell","text":"<pre><code># Download\nInvoke-WebRequest -Uri \"https://github.com/burnside-project/pg-collector/releases/latest/download/pg-collector-windows-amd64.zip\" -OutFile \"pg-collector.zip\"\n\n# Extract\nExpand-Archive -Path \"pg-collector.zip\" -DestinationPath \"C:\\Program Files\\pg-collector\"\n\n# Add to PATH (run as Administrator)\n$env:Path += \";C:\\Program Files\\pg-collector\"\n[Environment]::SetEnvironmentVariable(\"Path\", $env:Path, [EnvironmentVariableTarget]::Machine)\n</code></pre>"},{"location":"installation/#verify","title":"Verify","text":"<pre><code>pg-collector --version\n</code></pre>"},{"location":"installation/#docker-installation","title":"Docker Installation","text":""},{"location":"installation/#run-container","title":"Run Container","text":"<pre><code>docker run -d \\\n  --name pg-collector \\\n  -v /etc/pg-collector:/etc/pg-collector:ro \\\n  -v /var/lib/pg-collector:/var/lib/pg-collector \\\n  -p 8080:8080 \\\n  ghcr.io/burnside-project/pg-collector:latest \\\n  --config /etc/pg-collector/config.yaml\n</code></pre>"},{"location":"installation/#docker-compose","title":"Docker Compose","text":"<pre><code>version: '3.8'\nservices:\n  pg-collector:\n    image: ghcr.io/burnside-project/pg-collector:latest\n    restart: unless-stopped\n    volumes:\n      - ./config.yaml:/etc/pg-collector/config.yaml:ro\n      - ./certs:/etc/pg-collector/certs:ro\n      - collector-data:/var/lib/pg-collector\n    ports:\n      - \"8080:8080\"\n    command: --config /etc/pg-collector/config.yaml\n\nvolumes:\n  collector-data:\n</code></pre>"},{"location":"installation/#verify-download","title":"Verify Download","text":"<p>All releases include SHA256 checksums:</p> <pre><code># Download checksums\ncurl -LO https://github.com/burnside-project/pg-collector/releases/latest/download/checksums.txt\n\n# Verify\nsha256sum -c checksums.txt --ignore-missing\n</code></pre>"},{"location":"installation/#demo-build-installation","title":"Demo Build Installation","text":"<p>Want to try it first? The demo build lets you evaluate PG Collector without certificate setup\u2014just point it at your database and go.</p>"},{"location":"installation/#download-demo-build","title":"Download Demo Build","text":"Platform Download Linux amd64 <code>pg-collector-linux-amd64-demo.tar.gz</code> Linux arm64 <code>pg-collector-linux-arm64-demo.tar.gz</code> macOS Intel <code>pg-collector-darwin-amd64-demo.tar.gz</code> macOS Apple Silicon <code>pg-collector-darwin-arm64-demo.tar.gz</code> <pre><code># Example: Linux amd64\ncurl -LO https://github.com/burnside-project/pg-collector/releases/latest/download/pg-collector-linux-amd64-demo.tar.gz\ntar -xzf pg-collector-linux-amd64-demo.tar.gz\n\n# macOS Apple Silicon\ncurl -LO https://github.com/burnside-project/pg-collector/releases/latest/download/pg-collector-darwin-arm64-demo.tar.gz\ntar -xzf pg-collector-darwin-arm64-demo.tar.gz\n</code></pre>"},{"location":"installation/#demo-configuration","title":"Demo Configuration","text":"<pre><code># demo-config.yaml\ndatabases:\n  - name: local\n    postgres:\n      conn_string: \"postgres://user:password@localhost:5432/postgres\"\n      auth_method: password  # Only in demo builds\n\nlocal:\n  enabled: true\n  path: ./output\n  format: jsonl\n</code></pre>"},{"location":"installation/#run-demo","title":"Run Demo","text":"<pre><code>./pg-collector-demo --config demo-config.yaml\n</code></pre> <p>Metrics are written to the <code>./output</code> directory.</p>"},{"location":"installation/#demo-limitations","title":"Demo Limitations","text":"Feature Demo Production Password auth Allowed Not supported mTLS/IAM auth Supported Required Local output Yes Yes S3 output Yes Yes Platform output No Yes <p>For production, use the standard installation with mTLS or IAM authentication.</p>"},{"location":"installation/#directory-structure","title":"Directory Structure","text":"<p>After installation:</p> <pre><code>/usr/local/bin/\n\u2514\u2500\u2500 pg-collector          # Binary\n\n/etc/pg-collector/\n\u251c\u2500\u2500 config.yaml           # Configuration\n\u2514\u2500\u2500 certs/\n    \u251c\u2500\u2500 ca.crt            # CA certificate\n    \u251c\u2500\u2500 client.crt        # Client certificate\n    \u2514\u2500\u2500 client.key        # Client private key\n\n/var/lib/pg-collector/\n\u2514\u2500\u2500 buffer.db             # Local buffer (auto-created)\n</code></pre>"},{"location":"installation/#running-as-a-service","title":"Running as a Service","text":"<p>For production deployments, run PG Collector as a system service with self-healing capabilities. The service will automatically restart if it crashes and start at system boot.</p>"},{"location":"installation/#linux-systemd","title":"Linux (systemd)","text":"<pre><code># Create service file\nsudo cat &gt; /etc/systemd/system/pg-collector.service &lt;&lt; 'EOF'\n[Unit]\nDescription=PostgreSQL Metrics Collector\nAfter=network-online.target\nWants=network-online.target\nStartLimitIntervalSec=300\nStartLimitBurst=5\n\n[Service]\nType=simple\nUser=pg-collector\nGroup=pg-collector\nWorkingDirectory=/var/lib/pg-collector\nExecStart=/usr/local/bin/pg-collector --config /etc/pg-collector/config.yaml\n\n# Self-healing\nRestart=always\nRestartSec=5\nWatchdogSec=60\n\n# Resource limits\nMemoryMax=512M\nCPUQuota=50%\n\n# Logging\nStandardOutput=journal\nStandardError=journal\n\n[Install]\nWantedBy=multi-user.target\nEOF\n\n# Enable and start\nsudo systemctl daemon-reload\nsudo systemctl enable pg-collector\nsudo systemctl start pg-collector\n\n# Check status\nsudo systemctl status pg-collector\n</code></pre> <p>Self-Healing Features: - <code>Restart=always</code> - Automatically restarts on any failure - <code>RestartSec=5</code> - Waits 5 seconds before restart - <code>WatchdogSec=60</code> - systemd kills if no heartbeat in 60s - <code>MemoryMax=512M</code> - Prevents memory leaks from affecting system</p>"},{"location":"installation/#macos-launchd","title":"macOS (launchd)","text":"<pre><code># Create launch daemon\nsudo cat &gt; /Library/LaunchDaemons/com.burnsideproject.pg-collector.plist &lt;&lt; 'EOF'\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\"&gt;\n&lt;plist version=\"1.0\"&gt;\n&lt;dict&gt;\n    &lt;key&gt;Label&lt;/key&gt;\n    &lt;string&gt;com.burnsideproject.pg-collector&lt;/string&gt;\n    &lt;key&gt;ProgramArguments&lt;/key&gt;\n    &lt;array&gt;\n        &lt;string&gt;/usr/local/bin/pg-collector&lt;/string&gt;\n        &lt;string&gt;--config&lt;/string&gt;\n        &lt;string&gt;/etc/pg-collector/config.yaml&lt;/string&gt;\n    &lt;/array&gt;\n    &lt;key&gt;KeepAlive&lt;/key&gt;\n    &lt;true/&gt;\n    &lt;key&gt;ThrottleInterval&lt;/key&gt;\n    &lt;integer&gt;5&lt;/integer&gt;\n    &lt;key&gt;RunAtLoad&lt;/key&gt;\n    &lt;true/&gt;\n    &lt;key&gt;StandardOutPath&lt;/key&gt;\n    &lt;string&gt;/var/log/pg-collector/stdout.log&lt;/string&gt;\n    &lt;key&gt;StandardErrorPath&lt;/key&gt;\n    &lt;string&gt;/var/log/pg-collector/stderr.log&lt;/string&gt;\n&lt;/dict&gt;\n&lt;/plist&gt;\nEOF\n\n# Create directories\nsudo mkdir -p /var/log/pg-collector\n\n# Load and start\nsudo launchctl load /Library/LaunchDaemons/com.burnsideproject.pg-collector.plist\n\n# Check status\nsudo launchctl list | grep pg-collector\n</code></pre> <p>Self-Healing Features: - <code>KeepAlive=true</code> - Automatically restarts on any failure - <code>ThrottleInterval=5</code> - Minimum 5 seconds between restarts - <code>RunAtLoad=true</code> - Starts at system boot</p>"},{"location":"installation/#windows-nssm","title":"Windows (NSSM)","text":"<p>Use NSSM for reliable Windows service management:</p> <pre><code># Download NSSM\nInvoke-WebRequest -Uri \"https://nssm.cc/release/nssm-2.24.zip\" -OutFile \"nssm.zip\"\nExpand-Archive -Path \"nssm.zip\" -DestinationPath \"C:\\Tools\"\n\n# Install as service\nC:\\Tools\\nssm-2.24\\win64\\nssm.exe install pg-collector \"C:\\Program Files\\pg-collector\\pg-collector.exe\"\nC:\\Tools\\nssm-2.24\\win64\\nssm.exe set pg-collector AppParameters \"--config C:\\ProgramData\\pg-collector\\config.yaml\"\n\n# Self-healing settings\nC:\\Tools\\nssm-2.24\\win64\\nssm.exe set pg-collector AppExit Default Restart\nC:\\Tools\\nssm-2.24\\win64\\nssm.exe set pg-collector AppRestartDelay 5000\n\n# Logging\nC:\\Tools\\nssm-2.24\\win64\\nssm.exe set pg-collector AppStdout \"C:\\ProgramData\\pg-collector\\logs\\stdout.log\"\nC:\\Tools\\nssm-2.24\\win64\\nssm.exe set pg-collector AppStderr \"C:\\ProgramData\\pg-collector\\logs\\stderr.log\"\n\n# Start service\nC:\\Tools\\nssm-2.24\\win64\\nssm.exe start pg-collector\n</code></pre> <p>Alternative (native sc.exe):</p> <pre><code># Create service\nsc.exe create pg-collector binPath= \"C:\\Program Files\\pg-collector\\pg-collector.exe --config C:\\ProgramData\\pg-collector\\config.yaml\" start= auto\n\n# Configure self-healing (restart on failure)\nsc.exe failure pg-collector reset= 86400 actions= restart/5000/restart/5000/restart/30000\n\n# Start\nsc.exe start pg-collector\n</code></pre>"},{"location":"installation/#service-management-quick-reference","title":"Service Management Quick Reference","text":"Action Linux macOS Windows Start <code>sudo systemctl start pg-collector</code> <code>sudo launchctl start com.burnsideproject.pg-collector</code> <code>sc.exe start pg-collector</code> Stop <code>sudo systemctl stop pg-collector</code> <code>sudo launchctl stop com.burnsideproject.pg-collector</code> <code>sc.exe stop pg-collector</code> Status <code>sudo systemctl status pg-collector</code> <code>sudo launchctl list \\| grep pg-collector</code> <code>sc.exe query pg-collector</code> Logs <code>journalctl -u pg-collector -f</code> <code>tail -f /var/log/pg-collector/stdout.log</code> <code>Get-Content logs\\stdout.log -Tail 50 -Wait</code> Restart <code>sudo systemctl restart pg-collector</code> Unload then load plist <code>sc.exe stop pg-collector &amp;&amp; sc.exe start pg-collector</code>"},{"location":"installation/#health-check","title":"Health Check","text":"<p>All platforms support HTTP health checks:</p> <pre><code>curl http://localhost:8080/health\n# {\"status\":\"ok\",\"components\":{\"postgres\":{\"status\":\"ok\"}},\"timestamp\":\"...\"}\n</code></pre>"},{"location":"installation/#uninstallation","title":"Uninstallation","text":""},{"location":"installation/#linux","title":"Linux","text":"<pre><code>sudo systemctl stop pg-collector\nsudo systemctl disable pg-collector\nsudo rm /etc/systemd/system/pg-collector.service\nsudo systemctl daemon-reload\nsudo rm /usr/local/bin/pg-collector\nsudo rm -rf /etc/pg-collector\nsudo rm -rf /var/lib/pg-collector\nsudo userdel pg-collector\n</code></pre>"},{"location":"installation/#macos","title":"macOS","text":"<pre><code>sudo launchctl unload /Library/LaunchDaemons/com.burnsideproject.pg-collector.plist\nsudo rm /Library/LaunchDaemons/com.burnsideproject.pg-collector.plist\nsudo rm /usr/local/bin/pg-collector\nsudo rm -rf /etc/pg-collector\nsudo rm -rf /var/lib/pg-collector\nsudo rm -rf /var/log/pg-collector\n</code></pre>"},{"location":"installation/#windows","title":"Windows","text":"<pre><code># With NSSM\nC:\\Tools\\nssm-2.24\\win64\\nssm.exe stop pg-collector\nC:\\Tools\\nssm-2.24\\win64\\nssm.exe remove pg-collector confirm\n\n# Or with sc.exe\nsc.exe stop pg-collector\nsc.exe delete pg-collector\n\n# Remove files\nRemove-Item -Recurse -Force \"C:\\Program Files\\pg-collector\"\nRemove-Item -Recurse -Force \"C:\\ProgramData\\pg-collector\"\n</code></pre>"},{"location":"installation/#docker","title":"Docker","text":"<pre><code>docker stop pg-collector\ndocker rm pg-collector\ndocker rmi ghcr.io/burnside-project/pg-collector:latest\n</code></pre>"},{"location":"installation/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start - Get running quickly</li> <li>Configuration - Configure for your environment</li> <li>Security - Set up certificates</li> </ul>"},{"location":"monitoring/","title":"Monitoring Guide","text":"<p>Monitor PG Collector health and performance with built-in endpoints and Prometheus integration.</p>"},{"location":"monitoring/#health-endpoints","title":"Health Endpoints","text":"Endpoint Purpose <code>GET /health</code> Component health check <code>GET /status</code> Detailed status and buffer info <code>GET /livez</code> Kubernetes liveness probe <code>GET /readyz</code> Kubernetes readiness probe <code>GET /metrics</code> Prometheus metrics <code>GET /version</code> Build version information <code>GET /watchdog</code> Watchdog health status"},{"location":"monitoring/#health-check","title":"Health Check","text":"<pre><code>curl http://localhost:8080/health\n</code></pre> <p>Response: <pre><code>{\n  \"status\": \"ok\",\n  \"components\": {\n    \"postgres\": {\n      \"status\": \"ok\"\n    },\n    \"output\": {\n      \"status\": \"ok\"\n    }\n  },\n  \"timestamp\": \"2026-01-31T12:00:00Z\"\n}\n</code></pre></p> <p>Status values: - <code>ok</code> - All components healthy - <code>degraded</code> - One or more components unhealthy</p> <p>Component status values: - <code>ok</code> - Connected and working - <code>down</code> - Connection failed - <code>degraded</code> - Circuit breaker open - <code>unknown</code> - Not configured</p>"},{"location":"monitoring/#status-endpoint","title":"Status Endpoint","text":"<pre><code>curl http://localhost:8080/status\n</code></pre> <p>Response: <pre><code>{\n  \"buffer_depth\": 150,\n  \"last_push_time\": \"2026-01-31T12:00:00Z\",\n  \"postgres_connections\": 2,\n  \"is_draining\": false\n}\n</code></pre></p> <p>The status endpoint returns current buffer depth, last successful output time, active PostgreSQL connections, and whether the disk buffer is currently draining.</p>"},{"location":"monitoring/#kubernetes-probes","title":"Kubernetes Probes","text":""},{"location":"monitoring/#liveness-probe","title":"Liveness Probe","text":"<pre><code>curl http://localhost:8080/livez\n</code></pre> <p>Returns <code>200 OK</code> if alive, <code>503</code> if dead components detected.</p>"},{"location":"monitoring/#readiness-probe","title":"Readiness Probe","text":"<pre><code>curl http://localhost:8080/readyz\n</code></pre> <p>Returns <code>200 OK</code> if ready, <code>503</code> if required components are not connected.</p>"},{"location":"monitoring/#pod-configuration","title":"Pod Configuration","text":"<pre><code>livenessProbe:\n  httpGet:\n    path: /livez\n    port: 8080\n  initialDelaySeconds: 10\n  periodSeconds: 30\n\nreadinessProbe:\n  httpGet:\n    path: /readyz\n    port: 8080\n  initialDelaySeconds: 5\n  periodSeconds: 10\n</code></pre>"},{"location":"monitoring/#prometheus-metrics","title":"Prometheus Metrics","text":"<pre><code>curl http://localhost:8080/metrics\n</code></pre>"},{"location":"monitoring/#key-metrics","title":"Key Metrics","text":"Metric Type Description <code>pg_collector_up</code> Gauge Whether the collector is running (1 = up, 0 = down) <code>pg_collector_uptime_seconds</code> Gauge Time since collector started <code>pg_collector_samples_total</code> Counter Total samples collected <code>pg_collector_sample_errors_total</code> Counter Sample collection errors <code>pg_collector_buffer_memory_bytes</code> Gauge Memory buffer usage <code>pg_collector_buffer_disk_bytes</code> Gauge Disk buffer usage <code>pg_collector_output_success_total</code> Counter Successful outputs <code>pg_collector_output_errors_total</code> Counter Failed outputs <code>pg_collector_circuit_breaker_state</code> Gauge Circuit breaker state (0 = closed, 1 = half-open, 2 = open) <code>pg_collector_pg_query_duration_seconds</code> Histogram PostgreSQL query execution time <code>pg_collector_panics_recovered_total</code> Counter Total recovered panics"},{"location":"monitoring/#scrape-config","title":"Scrape Config","text":"<pre><code>scrape_configs:\n  - job_name: 'pg-collector'\n    static_configs:\n      - targets: ['pg-collector:8080']\n    scrape_interval: 30s\n    metrics_path: /metrics\n</code></pre>"},{"location":"monitoring/#alerting-rules","title":"Alerting Rules","text":""},{"location":"monitoring/#recommended-alerts","title":"Recommended Alerts","text":"<pre><code>groups:\n  - name: pg-collector\n    rules:\n      - alert: PGCollectorDown\n        expr: up{job=\"pg-collector\"} == 0\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"PG Collector is down\"\n          description: \"PG Collector has been unreachable for 5 minutes.\"\n\n      - alert: PGCollectorPostgresDown\n        expr: pg_collector_circuit_breaker_state{component=\"postgres\"} == 2\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"PostgreSQL connection circuit breaker is open\"\n          description: \"PG Collector cannot reach PostgreSQL. Circuit breaker is open.\"\n\n      - alert: PGCollectorDiskBufferActive\n        expr: pg_collector_buffer_disk_bytes &gt; 0\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Disk buffer is active\"\n          description: \"Samples are spilling to disk buffer, indicating output delivery issues.\"\n\n      - alert: PGCollectorNoSamples\n        expr: rate(pg_collector_samples_total[5m]) == 0\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"No samples collected\"\n          description: \"PG Collector has not collected any samples in the last 10 minutes.\"\n\n      - alert: PGCollectorDegraded\n        expr: pg_collector_health_status != 1\n        for: 2m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"PG Collector is degraded\"\n          description: \"One or more components are unhealthy.\"\n\n      - alert: PGCollectorBufferHigh\n        expr: pg_collector_buffer_disk_bytes &gt; 100000000\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Disk buffer exceeds 100 MB\"\n          description: \"Disk buffer is growing, indicating persistent output delivery failure.\"\n</code></pre>"},{"location":"monitoring/#prometheus-operator-servicemonitor","title":"Prometheus Operator ServiceMonitor","text":"<p>If you use the Prometheus Operator, create a <code>ServiceMonitor</code> to auto-discover PG Collector:</p> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: pg-collector\n  labels:\n    release: prometheus\nspec:\n  selector:\n    matchLabels:\n      app: pg-collector\n  endpoints:\n    - port: http\n      path: /metrics\n      interval: 30s\n</code></pre>"},{"location":"monitoring/#logging","title":"Logging","text":""},{"location":"monitoring/#configuration","title":"Configuration","text":"<pre><code>log:\n  level: info    # debug, info, warn, error\n  format: json   # json, console\n</code></pre>"},{"location":"monitoring/#view-logs","title":"View Logs","text":"<pre><code># Systemd\njournalctl -u pg-collector -f\n\n# Docker\ndocker logs -f pg-collector\n\n# Kubernetes\nkubectl logs -f deployment/pg-collector\n</code></pre>"},{"location":"monitoring/#structured-log-format","title":"Structured Log Format","text":"<p>When <code>format: json</code> is set (the default), PG Collector outputs structured JSON logs:</p> <pre><code>{\"level\":\"info\",\"ts\":\"2026-01-15T10:30:00Z\",\"msg\":\"sample collected\",\"sampler\":\"activity\",\"database\":\"prod-db-1\",\"duration_ms\":12}\n{\"level\":\"info\",\"ts\":\"2026-01-15T10:30:05Z\",\"msg\":\"sync complete\",\"samples\":847,\"latency_ms\":120}\n{\"level\":\"warn\",\"ts\":\"2026-01-15T10:31:00Z\",\"msg\":\"entering grace mode\",\"reason\":\"key service unreachable\"}\n</code></pre>"},{"location":"monitoring/#log-levels","title":"Log Levels","text":"Level Use <code>debug</code> Detailed diagnostic information (verbose, use for troubleshooting) <code>info</code> Normal operational events <code>warn</code> Recoverable issues that may need attention <code>error</code> Failures that prevent normal operation"},{"location":"monitoring/#important-log-patterns","title":"Important Log Patterns","text":"<p>Watch for these log messages to understand collector behavior:</p> Pattern Level Meaning <code>circuit breaker opened</code> WARN Too many failures to a component; retries paused <code>circuit breaker closed</code> INFO Component recovered; normal operation resumed <code>disk buffer activated</code> WARN Memory buffer full, samples writing to disk <code>disk buffer drained</code> INFO Disk buffer emptied, back to memory-only <code>device activated</code> INFO Activation successful, collecting started <code>entering grace mode</code> WARN Platform unreachable, using cached configuration <code>grace period expired</code> ERROR Collection stopped; needs reconnection <code>sync complete</code> INFO Successful data delivery to platform"},{"location":"monitoring/#watchdog","title":"Watchdog","text":"<p>The watchdog monitors collector health and detects stuck components.</p> <pre><code>curl http://localhost:8080/watchdog\n</code></pre> <p>Response:</p> <pre><code>{\n  \"status\": \"ok\",\n  \"components\": {\n    \"scheduler\": { \"status\": \"ok\", \"last_tick\": \"2026-01-15T10:30:00Z\" },\n    \"buffer\": { \"status\": \"ok\", \"depth\": 150 },\n    \"output\": { \"status\": \"ok\", \"last_success\": \"2026-01-15T10:29:55Z\" },\n    \"postgres\": { \"status\": \"ok\", \"connections\": 2 }\n  },\n  \"uptime_seconds\": 86400\n}\n</code></pre> <p>Component states:</p> State Description <code>ok</code> Component is healthy and operating normally <code>degraded</code> Component is operational but experiencing issues (e.g., circuit breaker half-open) <code>down</code> Component has failed (e.g., PostgreSQL unreachable) <code>unknown</code> Component is not configured or has not reported status"},{"location":"monitoring/#docker-health-check","title":"Docker Health Check","text":"<pre><code>services:\n  pg-collector:\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n</code></pre>"},{"location":"monitoring/#aws-albnlb","title":"AWS ALB/NLB","text":"<p>Target group health check: - Path: <code>/health</code> - Port: <code>8080</code> - Healthy threshold: 2 - Unhealthy threshold: 3 - Interval: 30 seconds</p>"},{"location":"plans/","title":"Subscription Plans","text":"<p>Compare PG Collector plans and choose the right one for your team.</p>"},{"location":"plans/#overview","title":"Overview","text":"<p>PG Collector offers subscription tiers designed to scale with your needs:</p> Tier Target Users Demo Evaluation and proof-of-concept Starter Individual developers, single database Pro Growing teams, multiple databases Business Medium organizations, advanced monitoring Enterprise Large organizations, maximum performance"},{"location":"plans/#feature-comparison","title":"Feature Comparison","text":"Feature Demo Starter Pro Business Enterprise Databases 1 1 Multiple Many Unlimited Sampling frequency Basic Standard Fast Faster Real-time Metric samplers Core (3) Core Extended Full All Output Local only Cloud Cloud Cloud Cloud + Custom Data retention Local files Standard Extended Long-term Custom AI insights \u2014 Summary Detailed Predictive Interactive Support Community Email Priority Email Business Hours 24/7"},{"location":"plans/#sampler-availability-by-plan","title":"Sampler Availability by Plan","text":"<p>PG Collector includes 12 PostgreSQL metric samplers organized into two groups.</p> <p>Core samplers cover essential database health. Extended samplers provide deeper insight for advanced monitoring and prediction.</p> Sampler Description Demo Starter Pro Business Enterprise activity Active sessions and wait events :white_check_mark: :white_check_mark: :white_check_mark: :white_check_mark: :white_check_mark: database Transaction rates, cache hits, deadlocks :white_check_mark: :white_check_mark: :white_check_mark: :white_check_mark: :white_check_mark: statements Query performance metrics :white_check_mark: :white_check_mark: :white_check_mark: :white_check_mark: :white_check_mark: bgwriter Checkpoint and buffer write stats :white_check_mark: :white_check_mark: :white_check_mark: replication Replication lag and sync state :white_check_mark: :white_check_mark: :white_check_mark: vacuum Dead tuples, vacuum progress, bloat risk :white_check_mark: :white_check_mark: :white_check_mark: locks Lock contention and blocking chains :white_check_mark: :white_check_mark: wal WAL generation and archiver stats :white_check_mark: :white_check_mark: slots Replication slot lag :white_check_mark: :white_check_mark: wal_receiver Standby receive lag :white_check_mark: statio Table and index I/O statistics :white_check_mark: bloat Table and index bloat estimation :white_check_mark:"},{"location":"plans/#security-features-by-plan","title":"Security Features by Plan","text":"Feature Demo Starter Pro Business Enterprise Basic query masking :white_check_mark: :white_check_mark: :white_check_mark: :white_check_mark: :white_check_mark: Custom masking rules :white_check_mark: :white_check_mark: :white_check_mark: PII detection Basic Basic Basic Full Full Audit logging :white_check_mark: :white_check_mark: SOC 2 compliance :white_check_mark: :white_check_mark: HIPAA support :white_check_mark: <p>Demo Tier \u2014 Free for Evaluation</p> <p>The Demo tier is completely free and requires no subscription. Use it to evaluate PG Collector locally with a single database and local file output. When you're ready for production, upgrade to a paid plan for cloud streaming, more databases, and AI-powered predictions.</p>"},{"location":"plans/#choosing-a-plan","title":"Choosing a Plan","text":"If you need... Recommended plan Local evaluation or POC Demo Single production database with basic monitoring Starter Multiple databases with replication and vacuum monitoring Pro Organization-wide monitoring with lock analysis and compliance Business Unlimited databases, real-time sampling, full security features Enterprise"},{"location":"plans/#upgrading-and-downgrading","title":"Upgrading and Downgrading","text":"<ul> <li>Upgrades take effect immediately \u2014 new features and limits are applied right away</li> <li>Downgrades take effect immediately \u2014 limits are reduced to the new plan</li> <li>Data retention \u2014 historical data beyond the new plan's limit is archived, not deleted</li> <li>Excess databases \u2014 if you have more databases than the new plan allows, excess databases are paused with a warning in logs</li> </ul> <p>To change your plan, visit the Burnside Dashboard and navigate to your subscription settings.</p>"},{"location":"plans/#related-documentation","title":"Related Documentation","text":"<ul> <li>Configuration Guide \u2014 Set up output modes and sampling</li> <li>Device Activation \u2014 How collectors activate and manage state</li> <li>Architecture Overview \u2014 How PG Collector works</li> <li>Quick Start \u2014 Get started in 5 minutes</li> </ul>"},{"location":"quick-start/","title":"Quick Start Guide","text":"<p>Get PG Collector running in 5 minutes.</p>"},{"location":"quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>PostgreSQL 12 or later</li> <li>Linux, macOS, or Windows</li> <li>API key from the Burnside Dashboard</li> </ul>"},{"location":"quick-start/#step-1-install","title":"Step 1: Install","text":"<pre><code># Linux (amd64)\ncurl -LO https://github.com/burnside-project/pg-collector/releases/latest/download/pg-collector-linux-amd64.tar.gz\ntar -xzf pg-collector-linux-amd64.tar.gz\nsudo mv pg-collector /usr/local/bin/\n</code></pre>"},{"location":"quick-start/#step-2-create-postgresql-user","title":"Step 2: Create PostgreSQL User","text":"<pre><code>-- Create monitoring user\nCREATE USER pgcollector;\n\n-- Grant monitoring permissions\nGRANT pg_monitor TO pgcollector;\n</code></pre>"},{"location":"quick-start/#step-3-configure","title":"Step 3: Configure","text":"<pre><code>sudo mkdir -p /etc/pg-collector\nsudo vi /etc/pg-collector/config.yaml\n</code></pre> <pre><code># API key from admin console\napi_key: \"pgc_pro_abc123...\"\n\ndatabases:\n  - name: Production\n    postgres:\n      conn_string: \"postgres://pgcollector@your-db:5432/postgres?sslmode=verify-full\"\n      auth_method: cert\n      tls:\n        mode: verify-full\n        ca_file: /etc/pg-collector/certs/ca.crt\n        cert_file: /etc/pg-collector/certs/client.crt\n        key_file: /etc/pg-collector/certs/client.key\n</code></pre>"},{"location":"quick-start/#step-4-set-up-certificates","title":"Step 4: Set Up Certificates","text":"<pre><code>sudo mkdir -p /etc/pg-collector/certs\nsudo cp ca.crt client.crt client.key /etc/pg-collector/certs/\nsudo chmod 600 /etc/pg-collector/certs/*.key\n</code></pre> <p>See Security Guide for certificate generation.</p>"},{"location":"quick-start/#step-5-validate-configuration","title":"Step 5: Validate Configuration","text":"<pre><code>pg-collector --check-config --config /etc/pg-collector/config.yaml\n</code></pre>"},{"location":"quick-start/#step-6-run","title":"Step 6: Run","text":"<pre><code># First run: auto-activates using api_key from config\npg-collector --config /etc/pg-collector/config.yaml\n</code></pre> <p>On first run, the collector: 1. Activates with the Burnside platform using your API key 2. Stores device state locally (survives restarts) 3. Begins collecting metrics</p>"},{"location":"quick-start/#step-7-verify","title":"Step 7: Verify","text":"<pre><code>curl http://localhost:8080/health\n</code></pre> <pre><code>{\n  \"status\": \"ok\",\n  \"components\": {\n    \"postgres\": {\"status\": \"ok\"}\n  }\n}\n</code></pre>"},{"location":"quick-start/#run-as-service","title":"Run as Service","text":"<pre><code>sudo systemctl enable pg-collector\nsudo systemctl start pg-collector\nsudo journalctl -u pg-collector -f\n</code></pre>"},{"location":"quick-start/#demo-mode","title":"Demo Mode","text":"<p>Quick evaluation without API key or certificates:</p>"},{"location":"quick-start/#download-demo-build","title":"Download Demo Build","text":"<pre><code># Linux\ncurl -LO https://github.com/burnside-project/pg-collector/releases/latest/download/pg-collector-linux-amd64-demo.tar.gz\ntar -xzf pg-collector-linux-amd64-demo.tar.gz\n\n# macOS\ncurl -LO https://github.com/burnside-project/pg-collector/releases/latest/download/pg-collector-darwin-arm64-demo.tar.gz\ntar -xzf pg-collector-darwin-arm64-demo.tar.gz\n</code></pre>"},{"location":"quick-start/#demo-configuration","title":"Demo Configuration","text":"<pre><code># demo-config.yaml\ndatabases:\n  - name: local\n    postgres:\n      conn_string: \"postgres://user:pass@localhost:5432/postgres?sslmode=disable\"\n      auth_method: password  # Only in demo builds\n\nlocal:\n  enabled: true\n  path: ./output\n  format: jsonl\n</code></pre>"},{"location":"quick-start/#run-demo","title":"Run Demo","text":"<pre><code>./pg-collector-demo --config demo-config.yaml\n\n# View metrics\nls ./output/\ntail -f ./output/activity/*.jsonl\n</code></pre>"},{"location":"quick-start/#demo-limitations","title":"Demo Limitations","text":"Feature Demo Production Password auth Yes No API key required No Yes Cloud output No Yes Local output Yes Yes"},{"location":"quick-start/#troubleshooting","title":"Troubleshooting","text":"Error Solution <code>device not activated</code> Add <code>api_key</code> to config file <code>password authentication failed</code> Check credentials in conn_string <code>connection refused</code> Verify PostgreSQL is running: <code>pg_isready</code> <code>certificate verify failed</code> Check TLS certificate paths"},{"location":"quick-start/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration Guide - All options</li> <li>Security Guide - Certificate setup</li> <li>Monitoring - Health endpoints</li> </ul>"},{"location":"roadmap/","title":"Roadmap","text":"<p>Last updated: January 2025</p> <p>This roadmap outlines our planned development for PG Collector and the Burnside observability platform. Priorities may shift based on customer feedback and market demands.</p>"},{"location":"roadmap/#legend","title":"Legend","text":"Status Meaning \u2705 Shipped \ud83d\udea7 In progress \ud83d\udccb Planned \ud83d\udd2c Research/Exploration"},{"location":"roadmap/#q1-2025-foundation","title":"Q1 2025 \u2014 Foundation","text":""},{"location":"roadmap/#pg-collector-agent","title":"PG Collector Agent","text":"Feature Status Notes PostgreSQL 14-17 support \u2705 Full compatibility mTLS authentication \u2705 Production-ready AWS IAM (RDS/Aurora) \u2705 Passwordless auth GCP IAM (Cloud SQL) \u2705 Passwordless auth Local-only demo mode \u2705 For evaluation Multi-platform binaries \u2705 Linux, macOS, Windows Systemd &amp; Docker deployment \u2705 Production-ready"},{"location":"roadmap/#cloud-platform","title":"Cloud Platform","text":"Feature Status Notes Claude 3.5 Haiku integration \u2705 AI-powered predictions Slack alerting \u2705 Real-time notifications PagerDuty integration \u2705 Incident escalation Tiered pricing (Starter/Pro/Enterprise) \u2705 Live"},{"location":"roadmap/#q2-2025-enterprise-scale","title":"Q2 2025 \u2014 Enterprise &amp; Scale","text":""},{"location":"roadmap/#multi-database-support","title":"Multi-Database Support","text":"Feature Status Target MySQL/MariaDB collector \ud83d\udea7 Q2 2025 AWS Aurora MySQL \ud83d\udccb Q2 2025 Azure Database for MySQL \ud83d\udccb Q2 2025"},{"location":"roadmap/#cloud-provider-integrations","title":"Cloud Provider Integrations","text":"Feature Status Target AWS CloudWatch metrics ingestion \ud83d\udea7 Q2 2025 AWS RDS Performance Insights correlation \ud83d\udccb Q2 2025 Azure Monitor integration \ud83d\udccb Q3 2025"},{"location":"roadmap/#enterprise-features","title":"Enterprise Features","text":"Feature Status Target SSO/SAML authentication \ud83d\udccb Q2 2025 Custom alert routing rules \ud83d\udccb Q2 2025 Audit logging \ud83d\udccb Q2 2025 Multi-tenant organization support \ud83d\udccb Q2 2025"},{"location":"roadmap/#q3-2025-intelligence-automation","title":"Q3 2025 \u2014 Intelligence &amp; Automation","text":""},{"location":"roadmap/#advanced-ai-capabilities","title":"Advanced AI Capabilities","text":"Feature Status Target Automated root cause analysis \ud83d\udccb Q3 2025 Query optimization recommendations \ud83d\udccb Q3 2025 Capacity planning forecasts \ud83d\udccb Q3 2025 Natural language query interface \ud83d\udd2c Q3-Q4 2025"},{"location":"roadmap/#automation-remediation","title":"Automation &amp; Remediation","text":"Feature Status Target Runbook automation triggers \ud83d\udccb Q3 2025 Terraform/Pulumi integration \ud83d\udccb Q3 2025 Auto-scaling recommendations \ud83d\udd2c Q4 2025"},{"location":"roadmap/#q4-2025-platform-expansion","title":"Q4 2025 \u2014 Platform Expansion","text":""},{"location":"roadmap/#additional-database-engines","title":"Additional Database Engines","text":"Feature Status Target MongoDB collector \ud83d\udd2c Q4 2025 Redis collector \ud83d\udd2c Q4 2025 Amazon DocumentDB \ud83d\udd2c Q4 2025 CockroachDB \ud83d\udd2c TBD"},{"location":"roadmap/#platform-capabilities","title":"Platform Capabilities","text":"Feature Status Target Custom dashboards \ud83d\udccb Q4 2025 API access (Pro/Enterprise) \ud83d\udccb Q4 2025 Webhook integrations \ud83d\udccb Q4 2025 Data export (S3, BigQuery) \ud83d\udccb Q4 2025"},{"location":"roadmap/#future-exploration","title":"Future Exploration","text":"<p>These items are on our radar but not yet committed to specific timelines:</p> <ul> <li>Edge ML inference \u2014 Run lightweight prediction models directly in the collector</li> <li>eBPF-based collection \u2014 Kernel-level observability without database queries</li> <li>Distributed tracing correlation \u2014 Connect database insights with APM tools</li> <li>Cost optimization insights \u2014 Cloud spend analysis tied to database patterns</li> <li>Compliance reporting \u2014 SOC 2, HIPAA, PCI-DSS report generation</li> </ul>"},{"location":"roadmap/#request-a-feature","title":"Request a Feature","text":"<p>Have a feature request or want to influence our roadmap?</p> <ul> <li>GitHub Issues: Open a feature request</li> <li>Email: product@burnsideproject.ai</li> <li>Customer portal: Enterprise customers can submit requests via the dashboard</li> </ul>"},{"location":"roadmap/#release-cadence","title":"Release Cadence","text":"<ul> <li>Patch releases (x.x.X): As needed for bug fixes and security updates</li> <li>Minor releases (x.X.0): Monthly, with new features and improvements</li> <li>Major releases (X.0.0): Quarterly, may include breaking changes</li> </ul> <p>Subscribe to release notifications by watching this repository or emailing updates@burnsideproject.ai.</p> <p>This roadmap is provided for informational purposes and does not constitute a commitment. Features and timelines are subject to change.</p>"},{"location":"security-policy/","title":"Security Policy","text":""},{"location":"security-policy/#supported-versions","title":"Supported Versions","text":"<p>We actively support security updates for the following versions:</p> Version Supported 1.0.x \u2705 Active support 0.2.x \u26a0\ufe0f Critical fixes only &lt; 0.2 \u274c No longer supported"},{"location":"security-policy/#reporting-a-vulnerability","title":"Reporting a Vulnerability","text":"<p>We take security vulnerabilities seriously. If you discover a security issue in PG Collector, please report it responsibly.</p>"},{"location":"security-policy/#how-to-report","title":"How to Report","text":"<p>Email: (mailto:security@burnsideproject.ai)</p> <p>Please include: - Description of the vulnerability - Steps to reproduce - Affected versions - Potential impact assessment - Any suggested remediation (optional)</p>"},{"location":"security-policy/#what-to-expect","title":"What to Expect","text":"Timeframe Action 24 hours Acknowledgment of your report 72 hours Initial assessment and severity classification 7 days Detailed response with remediation plan 30 days Target resolution for critical/high severity issues"},{"location":"security-policy/#severity-classification","title":"Severity Classification","text":"<p>We use CVSS 3.1 to classify vulnerabilities:</p> <ul> <li>Critical (9.0-10.0): Immediate action, patch within 7 days</li> <li>High (7.0-8.9): Priority fix, patch within 14 days</li> <li>Medium (4.0-6.9): Scheduled fix, patch within 30 days</li> <li>Low (0.1-3.9): Addressed in next regular release</li> </ul>"},{"location":"security-policy/#safe-harbor","title":"Safe Harbor","text":"<p>We consider security research conducted in good faith to be authorized. We will not pursue legal action against researchers who:</p> <ul> <li>Make a good faith effort to avoid privacy violations and data destruction</li> <li>Only interact with accounts you own or with explicit permission</li> <li>Do not exploit vulnerabilities beyond what is necessary to demonstrate the issue</li> <li>Report vulnerabilities promptly and do not disclose publicly until we've had reasonable time to address them</li> </ul>"},{"location":"security-policy/#recognition","title":"Recognition","text":"<p>We maintain a security acknowledgments page for researchers who report valid vulnerabilities. Let us know if you'd like to be credited.</p>"},{"location":"security-policy/#security-architecture","title":"Security Architecture","text":""},{"location":"security-policy/#authentication","title":"Authentication","text":"<p>PG Collector supports secure authentication methods designed for production environments:</p> Method Use Case Security Level mTLS Certificates Self-managed PostgreSQL Highest AWS IAM RDS, Aurora High (passwordless) GCP IAM Cloud SQL High (passwordless) <p>Production binaries do not support password authentication. Demo binaries support password auth for evaluation purposes only.</p>"},{"location":"security-policy/#data-in-transit","title":"Data in Transit","text":"<ul> <li>All communication with Burnside cloud infrastructure uses TLS 1.3</li> <li>PostgreSQL connections require <code>sslmode=verify-full</code> in production</li> <li>Certificate verification is mandatory; self-signed certificates are not supported in production mode</li> </ul>"},{"location":"security-policy/#data-at-rest","title":"Data at Rest","text":"<ul> <li>Telemetry data is encrypted at rest in our cloud infrastructure (AES-256)</li> <li>Local buffering (during network outages) uses encrypted storage</li> <li>No credentials are stored in configuration files when using IAM authentication</li> </ul>"},{"location":"security-policy/#minimal-privilege","title":"Minimal Privilege","text":"<p>PG Collector requires minimal PostgreSQL permissions:</p> <pre><code>-- Recommended role setup\nCREATE ROLE pgcollector WITH LOGIN;\nGRANT pg_monitor TO pgcollector;\nGRANT CONNECT ON DATABASE postgres TO pgcollector;\n</code></pre> <p>The collector: - Uses a maximum of 2 concurrent connections - Executes read-only queries with statement timeouts - Never modifies database state or schema</p>"},{"location":"security-policy/#network-security","title":"Network Security","text":"<ul> <li>Outbound connections only (no inbound ports required)</li> <li>Configurable egress endpoints for air-gapped environments</li> <li>Proxy support for environments with restricted internet access</li> </ul>"},{"location":"security-policy/#compliance","title":"Compliance","text":"<p>PG Collector is designed with compliance requirements in mind:</p> <ul> <li>SOC 2 Type II: Burnside cloud infrastructure (in progress)</li> <li>GDPR: Query masking prevents PII capture in statement analytics</li> <li>HIPAA: Available under BAA for healthcare customers (Enterprise tier)</li> </ul>"},{"location":"security-policy/#security-updates","title":"Security Updates","text":"<p>Security advisories are published via:</p> <ol> <li>GitHub Security Advisories</li> <li>Email notifications to registered customers</li> <li>Release notes for patched versions</li> </ol> <p>To receive security notifications, email security@burnsideproject.ai with subject \"Subscribe to security updates\".</p>"},{"location":"security-policy/#contact","title":"Contact","text":"<ul> <li>Security issues: security@burnsideproject.ai</li> <li>General support: support@burnsideproject.ai</li> <li>PGP Key: Available upon request for encrypted communications</li> </ul>"},{"location":"security/","title":"Security Guide","text":"<p>PG Collector is designed with security as a core principle. This guide covers authentication setup and security best practices.</p>"},{"location":"security/#authentication-methods","title":"Authentication Methods","text":"Method Use Case Security Level mTLS (Certificate) Self-managed PostgreSQL Highest AWS IAM Amazon RDS, Aurora High GCP IAM Google Cloud SQL High <p>Note: Password authentication is not supported in production builds. This is intentional - passwords in configuration files are a security risk.</p>"},{"location":"security/#demo-mode-exception","title":"Demo Mode Exception","text":"<p>For quick evaluation, the demo build (<code>pg-collector-demo</code>) allows password authentication:</p> <pre><code># Only in demo builds\npostgres:\n  conn_string: \"postgres://user:password@localhost:5432/postgres\"\n  auth_method: password\n</code></pre> <p>Demo builds are for evaluation only. For production, always use mTLS or IAM authentication.</p>"},{"location":"security/#mtls-certificate-authentication","title":"mTLS (Certificate Authentication)","text":""},{"location":"security/#overview","title":"Overview","text":"<p>mTLS (mutual TLS) provides: - Server verification - Client verifies the database server - Client verification - Server verifies the collector - Encryption - All traffic encrypted in transit - No passwords - Authentication via cryptographic certificates</p>"},{"location":"security/#certificate-requirements","title":"Certificate Requirements","text":"Certificate Purpose Location <code>ca.crt</code> Certificate Authority Collector + PostgreSQL <code>server.crt</code> + <code>server.key</code> PostgreSQL server identity PostgreSQL server <code>client.crt</code> + <code>client.key</code> Collector identity Collector host"},{"location":"security/#step-1-generate-certificates","title":"Step 1: Generate Certificates","text":"<p>For production, use a proper PKI solution: - step-ca (recommended for simplicity) - HashiCorp Vault PKI - AWS Private CA - Your organization's PKI</p> <p>For testing/development with OpenSSL:</p> <pre><code># Create CA\nopenssl genrsa -out ca.key 4096\nopenssl req -x509 -new -nodes -key ca.key -sha256 -days 3650 \\\n  -out ca.crt -subj \"/CN=PG Collector CA\"\n\n# Create client certificate (CN must match PostgreSQL username)\nopenssl genrsa -out client.key 2048\nopenssl req -new -key client.key -out client.csr \\\n  -subj \"/CN=pgcollector\"\nopenssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key \\\n  -CAcreateserial -out client.crt -days 365 -sha256\n</code></pre>"},{"location":"security/#step-2-configure-postgresql","title":"Step 2: Configure PostgreSQL","text":"<p>postgresql.conf: <pre><code>ssl = on\nssl_cert_file = '/path/to/server.crt'\nssl_key_file = '/path/to/server.key'\nssl_ca_file = '/path/to/ca.crt'\n</code></pre></p> <p>pg_hba.conf: <pre><code># Require certificate authentication for pgcollector\nhostssl all pgcollector 0.0.0.0/0 cert clientcert=verify-full\n</code></pre></p> <p>Reload PostgreSQL: <pre><code>sudo systemctl reload postgresql\n</code></pre></p>"},{"location":"security/#step-3-configure-pg-collector","title":"Step 3: Configure PG Collector","text":"<pre><code>postgres:\n  conn_string: \"postgres://pgcollector@db.burnsideproject.ai:5432/postgres?sslmode=verify-full\"\n  auth_method: cert\n  tls:\n    mode: verify-full\n    ca_file: /etc/pg-collector/certs/ca.crt\n    cert_file: /etc/pg-collector/certs/client.crt\n    key_file: /etc/pg-collector/certs/client.key\n</code></pre>"},{"location":"security/#step-4-set-file-permissions","title":"Step 4: Set File Permissions","text":"<pre><code>sudo mkdir -p /etc/pg-collector/certs\nsudo chown -R pg-collector:pg-collector /etc/pg-collector/certs\nsudo chmod 700 /etc/pg-collector/certs\nsudo chmod 600 /etc/pg-collector/certs/*.key\nsudo chmod 644 /etc/pg-collector/certs/*.crt\n</code></pre>"},{"location":"security/#step-5-verify-configuration","title":"Step 5: Verify Configuration","text":"<pre><code># Validate config syntax\npg-collector --check-config --config /etc/pg-collector/config.yaml\n\n# Test by running (Ctrl+C to stop after verifying connection)\npg-collector --config /etc/pg-collector/config.yaml\n</code></pre>"},{"location":"security/#aws-iam-authentication","title":"AWS IAM Authentication","text":"<p>For Amazon RDS and Aurora. See AWS Setup Guide for complete instructions.</p> <pre><code>postgres:\n  conn_string: \"postgres://pgcollector@mydb.xxx.us-east-1.rds.amazonaws.com:5432/postgres?sslmode=verify-full\"\n  auth_method: aws_iam\n  aws_iam:\n    enabled: true\n    region: \"us-east-1\"\n  tls:\n    mode: verify-full\n    ca_file: /etc/pg-collector/certs/rds-ca-bundle.pem\n</code></pre>"},{"location":"security/#gcp-iam-authentication","title":"GCP IAM Authentication","text":"<p>For Google Cloud SQL. See GCP Setup Guide for complete instructions.</p> <pre><code>postgres:\n  conn_string: \"postgres://pgcollector@/postgres?host=/cloudsql/project:region:instance\"\n  auth_method: gcp_iam\n  gcp_iam:\n    enabled: true\n</code></pre>"},{"location":"security/#security-best-practices","title":"Security Best Practices","text":""},{"location":"security/#1-minimal-permissions","title":"1. Minimal Permissions","text":"<p>Only grant necessary permissions:</p> <pre><code>CREATE USER pgcollector;\nGRANT pg_monitor TO pgcollector;\n\n-- Do NOT grant:\n-- - SUPERUSER\n-- - CREATE DATABASE\n-- - Any write permissions\n</code></pre>"},{"location":"security/#2-network-security","title":"2. Network Security","text":"<ul> <li>Run collector on same network as database</li> <li>Use private IPs, not public endpoints</li> <li>Restrict firewall to necessary IPs only</li> </ul> <pre><code># Example: only allow collector IP\nsudo ufw allow from 10.0.1.100 to any port 5432\n</code></pre>"},{"location":"security/#3-certificate-rotation","title":"3. Certificate Rotation","text":"<p>Rotate certificates before expiry:</p> <pre><code># Check certificate expiry\nopenssl x509 -in /etc/pg-collector/certs/client.crt -noout -dates\n</code></pre>"},{"location":"security/#4-secrets-management","title":"4. Secrets Management","text":"<p>Never store secrets in: - Configuration files - Environment variables visible in process lists - Version control</p> <p>Use: - Certificate files with restricted permissions - IAM roles (AWS/GCP) - Secrets managers</p>"},{"location":"security/#5-systemd-hardening","title":"5. Systemd Hardening","text":"<pre><code>[Service]\nUser=pg-collector\nGroup=pg-collector\nNoNewPrivileges=yes\nProtectSystem=strict\nProtectHome=yes\nReadWritePaths=/var/lib/pg-collector\nReadOnlyPaths=/etc/pg-collector\n</code></pre>"},{"location":"security/#troubleshooting","title":"Troubleshooting","text":""},{"location":"security/#certificate-errors","title":"Certificate Errors","text":"<pre><code># Verify certificate chain\nopenssl verify -CAfile ca.crt client.crt\n\n# Check certificate details\nopenssl x509 -in client.crt -text -noout\n</code></pre>"},{"location":"security/#common-issues","title":"Common Issues","text":"Error Cause Solution <code>certificate verify failed</code> CA mismatch Use correct ca.crt <code>private key mismatch</code> Wrong key file Regenerate cert/key pair <code>certificate authentication failed</code> CN doesn't match username CN in cert must equal PostgreSQL username"},{"location":"security/#query-masking","title":"Query Masking","text":"<p>PG Collector masks sensitive values in SQL queries before transmission.</p>"},{"location":"security/#masking-levels","title":"Masking Levels","text":"Level Description Tier <code>none</code> No masking - <code>basic</code> Mask string literals and numbers Starter <code>full</code> Mask all values including identifiers Pro <code>custom</code> User-defined patterns Enterprise"},{"location":"security/#configuration","title":"Configuration","text":"<pre><code>security:\n  query_masking_level: basic\n\n  # Custom patterns (Enterprise)\n  masking_patterns:\n    - \"password\"\n    - \"secret\"\n    - \"token\"\n    - \"api_key\"\n</code></pre>"},{"location":"security/#example","title":"Example","text":"<p>Original query: <pre><code>SELECT * FROM users WHERE email = 'john@burnsideproject.ai' AND password = 'secret123'\n</code></pre></p> <p>Masked (basic): <pre><code>SELECT * FROM users WHERE email = '?' AND password = '?'\n</code></pre></p>"},{"location":"security/#pii-detection-enterprise","title":"PII Detection (Enterprise)","text":"<p>Automatically detect and mask personally identifiable information.</p> <pre><code>security:\n  pii_detection: true\n</code></pre> <p>Detected patterns: - Email addresses - Phone numbers - Social Security Numbers - Credit card numbers</p>"},{"location":"security/#audit-logging-enterprise","title":"Audit Logging (Enterprise)","text":"<p>Log security-relevant events for compliance.</p> <pre><code>security:\n  audit_logging: true\n  audit_log_path: /var/log/pg-collector/audit.log\n</code></pre> <p>Logged events: - Activation/deactivation - Configuration changes - Authentication failures - Query vault access</p>"},{"location":"security/#ip-allowlist-enterprise","title":"IP Allowlist (Enterprise)","text":"<p>Restrict HTTP endpoint access to specific IP addresses or CIDR ranges. This provides network-level access control for the collector's health and metrics endpoints.</p>"},{"location":"security/#configuration_1","title":"Configuration","text":"<pre><code>security:\n  ip_allowlist:\n    enabled: true\n    allowlist:\n      - \"10.0.0.0/8\"           # Private network\n      - \"192.168.1.100/32\"     # Single IP\n      - \"2001:db8::/32\"        # IPv6 CIDR\n</code></pre>"},{"location":"security/#features","title":"Features","text":"<ul> <li>CIDR notation: Supports both IPv4 and IPv6 ranges</li> <li>Single IPs: Automatically converts to /32 (IPv4) or /128 (IPv6)</li> <li>Proxy headers: Reads <code>X-Forwarded-For</code> and <code>X-Real-IP</code> for client IP</li> <li>Audit logging: Blocked requests logged to audit log (if enabled)</li> <li>Runtime management: Add/remove CIDRs without restart (via API)</li> </ul>"},{"location":"security/#response","title":"Response","text":"<p>When an IP is blocked, the endpoint returns: <pre><code>HTTP/1.1 403 Forbidden\n</code></pre></p>"},{"location":"security/#tier-enforcement-critical","title":"Tier Enforcement (Critical)","text":"<p>PG Collector enforces tier limits using server-provided tier values. This prevents tier spoofing where a user might try to bypass limits by editing the local configuration.</p>"},{"location":"security/#how-it-works","title":"How It Works","text":"<ol> <li>On activation, the Key Service returns the authorized tier for the API key</li> <li>The collector always uses the server-provided tier, ignoring any local config overrides</li> <li>If local config tier differs from server tier, a warning is logged</li> </ol>"},{"location":"security/#security-implications","title":"Security Implications","text":"<ul> <li>Cannot bypass tier limits via local configuration</li> <li>Cannot access Enterprise features with a Starter API key</li> <li>Audit logged when tier mismatch detected</li> <li>Automatic enforcement - no manual configuration required</li> </ul>"},{"location":"security/#security-checklist","title":"Security Checklist","text":"<ul> <li>[ ] Using certificate or IAM authentication (no passwords)</li> <li>[ ] TLS mode set to <code>verify-full</code></li> <li>[ ] Certificate files have restricted permissions (600)</li> <li>[ ] PostgreSQL user has minimal permissions (pg_monitor only)</li> <li>[ ] Network access restricted to necessary IPs</li> <li>[ ] IP allowlist configured (Enterprise)</li> <li>[ ] Systemd service hardened</li> <li>[ ] Certificate rotation scheduled</li> <li>[ ] Query masking enabled</li> <li>[ ] PII detection enabled (if Enterprise)</li> </ul>"},{"location":"troubleshooting/","title":"Troubleshooting Guide","text":"<p>Common issues and solutions for PG Collector.</p>"},{"location":"troubleshooting/#quick-diagnostics","title":"Quick Diagnostics","text":"<pre><code># Check service status\nsudo systemctl status pg-collector\n\n# View recent logs\nsudo journalctl -u pg-collector -n 50\n\n# Validate configuration\npg-collector --check-config --config /etc/pg-collector/config.yaml\n\n# Check health endpoint\ncurl http://localhost:8080/health\n\n# Check detailed status\ncurl http://localhost:8080/status\n</code></pre>"},{"location":"troubleshooting/#activation-issues","title":"Activation Issues","text":""},{"location":"troubleshooting/#device-not-activated","title":"Device Not Activated","text":"<p>Symptoms: <pre><code>device not activated - add 'api_key' to config file\n</code></pre></p> <p>Solution:</p> <p>Add your API key to the configuration file:</p> <pre><code>api_key: \"pgc_pro_abc123...\"\n</code></pre> <p>Get your API key from the Admin Console.</p>"},{"location":"troubleshooting/#activation-failed","title":"Activation Failed","text":"<p>Symptoms: <pre><code>activation failed: invalid API key\n</code></pre></p> <p>Solutions:</p> <ol> <li>Verify API key format - should start with <code>pgc_</code></li> <li>Check API key is active - not expired or revoked</li> <li>Check network connectivity to Key Service</li> </ol>"},{"location":"troubleshooting/#device-revoked","title":"Device Revoked","text":"<p>Symptoms: <pre><code>device has been revoked\n</code></pre></p> <p>Solution:</p> <p>Contact your administrator to re-enable or generate a new API key.</p> <p>To reset local state: <pre><code>pg-collector --deactivate\n</code></pre></p>"},{"location":"troubleshooting/#connection-issues","title":"Connection Issues","text":""},{"location":"troubleshooting/#cannot-connect-to-postgresql","title":"Cannot Connect to PostgreSQL","text":"<p>Symptoms: <pre><code>ERROR: connection refused\nERROR: connection timed out\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Check network connectivity: <pre><code>nc -zv db.burnsideproject.ai 5432\n</code></pre></p> </li> <li> <p>Check PostgreSQL is listening: <pre><code>sudo ss -tlnp | grep 5432\n</code></pre></p> </li> <li> <p>Check pg_hba.conf allows connection: <pre><code>hostssl all pgcollector YOUR_IP/32 cert\n</code></pre></p> </li> <li> <p>Check firewall rules</p> </li> </ol>"},{"location":"troubleshooting/#certificate-authentication-failed","title":"Certificate Authentication Failed","text":"<p>Symptoms: <pre><code>FATAL: certificate authentication failed for user \"pgcollector\"\nSSL error: certificate verify failed\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Verify certificate CN matches username: <pre><code>openssl x509 -in /etc/pg-collector/certs/client.crt -noout -subject\n# Should show: subject= /CN=pgcollector\n</code></pre></p> </li> <li> <p>Verify certificate chain: <pre><code>openssl verify -CAfile /etc/pg-collector/certs/ca.crt \\\n  /etc/pg-collector/certs/client.crt\n</code></pre></p> </li> <li> <p>Check certificate expiry: <pre><code>openssl x509 -in /etc/pg-collector/certs/client.crt -noout -dates\n</code></pre></p> </li> <li> <p>Check file permissions: <pre><code>ls -la /etc/pg-collector/certs/\n# .key files should be 600\n# .crt files should be 644\n</code></pre></p> </li> <li> <p>Test with psql first: <pre><code>psql \"host=db.burnsideproject.ai port=5432 dbname=postgres user=pgcollector \\\n  sslmode=verify-full \\\n  sslcert=/etc/pg-collector/certs/client.crt \\\n  sslkey=/etc/pg-collector/certs/client.key \\\n  sslrootcert=/etc/pg-collector/certs/ca.crt\"\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#aws-iam-authentication-failed","title":"AWS IAM Authentication Failed","text":"<p>Symptoms: <pre><code>FATAL: PAM authentication failed\nERROR: could not get IAM auth token\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Check IAM authentication is enabled on RDS: <pre><code>aws rds describe-db-instances --db-instance-identifier mydb \\\n  --query 'DBInstances[0].IAMDatabaseAuthenticationEnabled'\n</code></pre></p> </li> <li> <p>Verify user has rds_iam role: <pre><code>SELECT rolname FROM pg_roles WHERE rolname = 'pgcollector';\n</code></pre></p> </li> <li> <p>Check IAM policy resource ARN - Region, Account ID, DBI resource ID correct?</p> </li> </ol>"},{"location":"troubleshooting/#service-issues","title":"Service Issues","text":""},{"location":"troubleshooting/#service-wont-start","title":"Service Won't Start","text":"<p>Symptoms: <pre><code>systemctl status pg-collector\n\u25cf pg-collector.service\n   Active: failed\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Check logs: <pre><code>sudo journalctl -u pg-collector -n 100 --no-pager\n</code></pre></p> </li> <li> <p>Validate configuration: <pre><code>pg-collector --check-config --config /etc/pg-collector/config.yaml\n</code></pre></p> </li> <li> <p>Check file permissions: <pre><code>ls -la /etc/pg-collector/\nls -la /var/lib/pg-collector/\n</code></pre></p> </li> <li> <p>Run manually to see errors: <pre><code>sudo -u pg-collector pg-collector --config /etc/pg-collector/config.yaml\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/#high-resource-usage","title":"High Resource Usage","text":"<p>Memory: - Check configured buffer limits - Reduce sampling frequency</p> <p>CPU: - Reduce sampling frequency - Check for output backpressure</p>"},{"location":"troubleshooting/#health-check-issues","title":"Health Check Issues","text":""},{"location":"troubleshooting/#health-endpoint-returns-degraded","title":"Health Endpoint Returns Degraded","text":"<p>Symptoms: <pre><code>{\n  \"status\": \"degraded\",\n  \"components\": {\n    \"postgres\": {\"status\": \"down\"}\n  }\n}\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Check detailed status: <pre><code>curl http://localhost:8080/status | jq\n</code></pre></p> </li> <li> <p>Check PostgreSQL connectivity</p> </li> <li> <p>Check logs for specific errors</p> </li> </ol>"},{"location":"troubleshooting/#common-error-messages","title":"Common Error Messages","text":"Error Cause Solution <code>device not activated</code> Missing api_key Add api_key to config <code>connection refused</code> PostgreSQL not reachable Check network/firewall <code>certificate verify failed</code> Wrong CA certificate Use correct ca.crt <code>authentication failed</code> Wrong auth method Check auth_method config <code>permission denied</code> Missing grants Grant pg_monitor role <code>timeout</code> Query too slow Increase query_timeout <code>grace period expired</code> Offline too long Restore network to Key Service"},{"location":"troubleshooting/#getting-help","title":"Getting Help","text":"<p>If you're still having issues:</p> <ol> <li> <p>Check version: <pre><code>pg-collector --version\n</code></pre></p> </li> <li> <p>Check logs: <pre><code>sudo journalctl -u pg-collector --since \"1 hour ago\"\n</code></pre></p> </li> <li> <p>Open an issue: GitHub Issues</p> </li> <li> <p>Contact support: support@burnsideproject.ai</p> </li> </ol> <p>Include: - PG Collector version - PostgreSQL version - Operating system - Configuration (redact api_key) - Error messages - Steps to reproduce</p>"}]}